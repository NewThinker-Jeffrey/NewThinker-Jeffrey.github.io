[TOC]

# 粒子滤波

# 基础篇


## 预备知识 (1) - 基础采样方法

大数定律指出，在多次重复试验中，某个事件发生的频率$f$将收敛(正比)于其发生的概率$p$；
换一种不严格但更容易记住和理解的说法，就是：**频率的期望等于概率**。

这指导了我们可以用很多方式来采样。
如果我们需要采集一组符合分布$p(x)$的样本，那只要我们能设计一个采样流程，使得该流程结束后，**任何两个事件，如$(x=x_1)$与$(x=x_2)$，的发生频率的期望之比$\frac{E[f(x_1)]}{E[f(x_2)]}$，等于这两个事件的概率之比$\frac{p(x_1)}{p(x_2)}$**，即
$$\frac{E[f(x_1)]}{E[f(x_2)]}=\frac{p(x_1)}{p(x_2)}$$
我们就可以认为，经过这个采样流程得到的样本符合分布$p(x)$。为了方便下文中以**采样准则**来称呼上面这个采样规则。

### 直接采样，CDF采样
如果$p(x)$形式比较简单，比如$x$是一维的且可以计算出累计分布函数(CDF: cumulative distribution function)及其逆函数，那我们可以通过计算机产生一个服从$[0,1]$之间均匀分布($\mathcal{U}_{[0,1]}$)的随机数并映射到CDF上，实现对$p(x)$的直接采样。
如果我们定义一轮采样流程为：连续从$p(x)$中抽取$n$个样本。那么这个流程完成后，$x_1$被抽到的频率(或次数) 的期望是 $E[f(x_1)]=np(x_1)$，$x_2$被抽到的频率(或次数) 的期望是 $E[f(x_2)]=np(x_2)$。显然这满足$\frac{E[f(x_1)]}{E[f(x_2)]}=\frac{p(x_1)}{p(x_2)}$，因此通过这种直接抽样方式可以得到符合分布$p(x)$的一组样本。


### 接受/拒绝 采样 
如果$p(x)$形式比较复杂，我们就无法对其直接采样；
我们可以从另一个容易采样的 proposal 分布$q(x)$中先采样一组点，然后扔掉一些，使得剩下的点满足目标分布$p(x)$。
具体方法如下：
首先，选定一个大于$1$的正数$k$，使得对于所有的$x$总有：$kq(x)\ge p(x)$。并定义$\alpha(x)=\frac{p(x)}{kq(x)}$，$\alpha$被称为接受率。
然后，从$q(x)$中采样一个点$X$ (采样 $X\sim q(x)$)，再从$[0,1]$均匀分布中抽取一个随机数$\mu$ (采样 $\mu\sim \mathcal{U}_{[0,1]}$)，如果$\mu\le\alpha(X)$，则接受样本$X$；否则丢弃$X$。
这样，进行$n$次抽样后，对于任意两个点$x_1$和$x_2$，它们被抽到的次数/频率的期望分别是：
$$
E[f(x_1)]=\sum_{i=1}^{n}\alpha(x_1)q(x_1)=\sum_{i=1}^{n}\frac{p(x_1)}{kq(x_1)}q(x_1)=\frac{np(x_1)}{k} \\
E[f(x_2)]=\sum_{i=1}^{n}\alpha(x_2)q(x_2)=\sum_{i=1}^{n}\frac{p(x_2)}{kq(x_2)}q(x_2)=\frac{np(x_2)}{k}
$$
显然这满足之前提到的采样准则： $\frac{E[f(x_1)]}{E[f(x_2)]}=\frac{p(x_1)}{p(x_2)}$。因此此方法可以获得符合$p(x)$的一组样本。
这种采样方法的一个严重缺陷就是，如果proposal分布$q(x)$选得不合适，那么在很多区域会出现接受率很低的情况，这意味着有大量的采样是被浪费掉的，从而降低采样效率。比如下面的图示中方框圈起的区域。而且，一定要**保证接受率$\alpha(x)=\frac{p(x)}{kq(x)}$始终小于或等于$1$**，但这样的$k$一般并不容易找到。
如果对于某些$x$，有接受率$\alpha(x)>1$，就会出现采样偏差。

> 下图中，蓝色曲线是 proposal 分布 $q(z)$ 的概率密度函数曲线，红色曲线是目标分布 $\tilde p(z)$的概率密度函数曲线。
接受/拒绝 采样，本质上，就是先从下图中蓝色曲线与$z$轴围成的区域中均匀采样，然后只保留落在白色区域（红色曲线与$z$轴围成的区域）中的点。
这要求，白色区域必须包含在灰色区域内！即对于任意的 $z$， 有$kq(z)\ge \tilde p(z)$，接受率$\alpha(z)\le 1$。
否则白色区域就不能被采样点完全覆盖，采样结果就是有偏差的。
![](https://github.com/NewThinker-Jeffrey/Figures/raw/main/figures/35b1a470b8e46653e7c3c767fa748a34.jpg)
 

### 重要性采样
重要性采样可以克服“接受/拒绝采样”中接受率低的问题，但需要更每个样本分配不同权重；
我们可以从 proposal 分布$q(x)$中先采样一组点，然后为每个点分配权重，使得带上权重后的样本点能符合$p(x)$分布，这个权重就是重要性权重，而这种间接采样的方法就是重要性采样法；
我们每从$q(x)$中抽取一个样本$X$ (采样 $X\sim q(x)$)，比如抽到的是$X=x_i$，那此样本的重要性权重定义为 $$w(x_i) = \frac{p(x_i)}{q(x_i)}$$
我们每从$q(x)$中抽到一次$x_i$，就看做是从$p(x)$中抽到了$w(x_i)$次$x_i$，即认为$f(x_i)$增加了$w(x_i)$；
如果我们定义一轮采样流程为：连续从$q(x)$中抽取$n$个样本，并为每个样本按照重要性权重记录出现频率。那么这个流程完成后，对于任意的 $x_1$ 和 $x_2$，我们有：
$$
E[f(x_1)]=w(x_1)nq(x_1)=\frac{p(x_1)}{q(x_1)}nq(x_1)=np(x_1)\\
E[f(x_2)]=w(x_2)nq(x_2)=\frac{p(x_2)}{q(x_2)}nq(x_2)=np(x_2)
$$
此时依然满足$\frac{E[f(x_1)]}{E[f(x_2)]}=\frac{p(x_1)}{p(x_2)}$，因此重要性采样方法可以获得符合$p(x)$的一组样本。


### 有限混合分布 (finite mixture distribution)及其采样

- 定义
> 如果一个分布可表达为多个其他分布的加权和，比如：
$$
P(x) = \sum_{i=1}^{n}{\frac{w_i}{W}p_i(x)} = \sum_{i=1}^{n}{\widehat{w_i}p_i(x)}
$$
（其中$w_i$是第$i$个**子分布**$p_i(x)$的权重，$W=(\sum_i{w_i})$是所有分布的权重之和，$\widehat{w_i}$是归一化后的权重）
则$P(x)$ 就是一个**有限混合分布 (finite mixture distribution)**。

- **结论0** ：从各个子分布$p_1(x),p_2(x)...p_n(x)$中分别抽取一个样本，得到样本集 $X=\{X_1,X_2...X_n\}$，并分别分配权重$\{\widehat{w_1},\widehat{w_2}...\widehat{w_n}\}$，则这些带权重的样本符合分布 $P(x)$。
> Proof
定义一轮采样流程为：依次从子分布 $p_1(x),p_2(x)...p_n(x)$中分别抽取一个样本，得到样本集 $X=\{X_1,X_2...X_n\}$，并分别分配权重$\{\widehat{w_1},\widehat{w_2}...\widehat{w_n}\}$ （即相当于我们抽取到了$\widehat{w_1}$次$X_1$、$\widehat{w_2}$次$X_2$...）。
那么，对于任意的 $x_k$ 和 $x_j$，我们有：

$$
E[f(x_k)]=\sum_{i=1}^{n}{\widehat{w_i}p_i(x_k)}=P(x_k)\\
E[f(x_j)]=\sum_{i=1}^{n}{\widehat{w_i}p_i(x_j)}=P(x_j) $$
此时满足$\frac{E[f(x_k)]}{E[f(x_j)]}=\frac{P(x_k)}{P(x_j)}$

结论0给出了有限混合分布的一种分解式的采样方法，但需要对各子分布$p_i(x)$依次直接采样。
如果$p_i(x)$难以直接采样，同样可以借助重要性采样方法。

- **结论1** ：设$q_1(x),q_2(x)...q_n(x)$ 分别是$p_1(x),p_2(x)...p_n(x)$的proposal分布，若从各个proposal子分布$q_1(x),q_2(x)...q_n(x)$中分别抽取一个样本，得到样本集 $X=\{X_1,X_2...X_n\}$，并分别分配权重（**未归一化权重**）$\{\widehat{w_1}s_1(X_1),\widehat{w_2}s_2(X_2),...,\widehat{w_n}s_n(X_n)\}$，则这些带权重的样本符合分布 $P(x)$。
其中$s_i(x)=\frac{p_i(x)}{q_i(x)}$是第$i$个子分布的重要性函数，$\widehat{w_i}s_i(X_i)$是第$i$个样本$X_i$的总权重。
>  Proof
定义一轮采样流程为：依次从proposal子分布 $q_1(x),q_2(x)...q_n(x)$中分别抽取一个样本，得到样本集 $X=\{X_1,X_2...X_n\}$，并分别分配权重$\{\widehat{w_1}s_1(X_1),\widehat{w_2}s_2(X_2),...,\widehat{w_n}s_n(X_n)\}$ （即相当于我们抽取到了$\widehat{w_1}s_1(X_1)$次$X_1$、$\widehat{w_2}s_2(X_2)$次$X_2$...）。
那么，对于任意的 $x_k$ 和 $x_j$，我们有：

$$
E[f(x_k)]=\sum_{i=1}^{n}{\widehat{w_i}s_i(x_k)q_i(x_k)}=\sum_{i=1}^{n}{\widehat{w_i}\frac{p_i(x_k)}{q_i(x_k)}q_i(x_k)}=\sum_{i=1}^{n}{\widehat{w_i}p_i(x_k)}=WP(x_k)\\
E[f(x_j)]=\sum_{i=1}^{n}{\widehat{w_i}s_i(x_j)q_i(x_j)}=\sum_{i=1}^{n}{\widehat{w_i}\frac{p_i(x_j)}{q_i(x_j)}q_i(x_j)}=\sum_{i=1}^{n}{\widehat{w_i}p_i(x_j)}=WP(x_j)$$

其中$W$代表总权重。此时满足$\frac{E[f(x_k)]}{E[f(x_j)]}=\frac{P(x_k)}{P(x_j)}$

## 粒子化

### 粒子化求期望
设随机变量$x$服从分布$p(x)$，$g(x)$是$x$的一个函数，那么$g(x)$函数值的期望$E[g(x)]$可以用积分式表达如下：
$$
E[g(x)]=\int_{\Omega_x}p(x)g(x)d\Omega_x
$$
上面的积分通常难以求解。但可以使用蒙特卡罗方法得到$E[g(x)]$的近似值。
- **结论2** ：设${X_1,X_2,X_3...,X_n}$是从分布$p(x)$中采样的、能充分反应分布$p(x)$的一组样本集，每个样本的权重分别为$\{w_1,w_2...w_n\}$，则$$E[g(x)]\approx \sum_{i=1}^{n}{(w_i/W)g(X_i)},\qquad where\quad W=\sum_{i=1}^{n}w_i$$

### 粒子化求卷积
$x$的函数$g(x)$与其分布函数值$p(x)$的卷积可以用积分式表达如下：
$$
(p*g)(x)=\int_{\Omega_x}p(\tau)g(x-\tau)d\Omega_x
$$
这个积分通常无法求出解析解，但可以使用蒙特卡罗方法得到$(p*g)(x)$的近似表达式。
- **结论3** ：设${X_1,X_2,X_3...,X_n}$是从分布$p(x)$中采样的、能充分反应分布$p(x)$的一组样本集，每个样本的权重分别为$\{w_1,w_2...w_n\}$，则$$(p*g)(x)\approx \sum_{i=1}^{n}{(w_i/W)g(x-X_i)},\qquad where\quad W=\sum_{i=1}^{n}w_i$$

### 粒子化分布的表达式
上面我们提到了在求一个函数$g(x)$的期望或与分布函数$p(x)$的卷积等**积分类操作**时，可以多个粒子来近似描述一个分布。
我们现在也给这种粒子化的分布一个正式的表达式，设${X_1,X_2,X_3...,X_n}$是从分布$p(x)$中采样的、能充分反应分布$p(x)$的一组样本集，每个样本的权重分别为$\{w_1,w_2...w_n\}$，则粒子化表达式为：
$$
\widehat{p}(x)=\sum_{i=1}^{n}{(w_i/W)\delta(x-X_i)}
$$
其中使用了$\delta$函数来表示离散的分布。


这样，我们就可以重写**结论2**和**结论3**如下：
$$
E_{p}[g(x)]=\int_{\Omega_x}p(x)g(x)d\Omega_x\approx \int_{\Omega_x}\widehat{p}(x)g(x)d\Omega_x=E_{\widehat{p}}[g(x)]\\
(p*g)(x)=\int_{\Omega_x}p(\tau)g(x-\tau)d\Omega_x\approx \int_{\Omega_x}\widehat{p}(\tau)g(x-\tau)d\Omega_x=(\widehat{p}*g)(x)
$$

由于$p(x)$与$\widehat{p}(x)$在求均值和卷积等**积分类操作**时的近似等价性，即$E_{p}[g(x)]\approx E_{\widehat{p}}[g(x)]$和$(p*g)(x)\approx (\widehat{p}*g)(x)$，我们认为$\widehat{p}(x)$是$p(x)$ 的一个近似分布，记为
$$
p(x)\sim \widehat{p}(x)
$$
这里没有使用约等号"$\approx$"，是因为在**概率密度数值**上，$p(x)\not \approx \widehat{p}(x)$。
**它们的近似性只在求积分类操作时体现**。

当粒子足够多，即$n$足够大时，$\widehat{p}(x)$就能较准确地描述原分布$p(x)$；
> 其实，仅仅由 $n$ 足够大并不能保证这些粒子能近似描述分布$p(x)$，还取决于各粒子的权重$w_i$ 是否均衡。 
如果各粒子权重都差不多，那么$n$足够大时基本可以保证$\widehat{p}(x)$较准确地描述分布$p(x)$；
而如果各粒子权重差异很大，比如第一个粒子权重几乎为1而其他粒子权重都为0时，相当于只有第一个粒子在起作用，即只有一个**有效粒子**，这时$p(x)$的分布信息将严重丢失，这些粒子已不能近似描述$p(x)$。
因此，必须有足够数量的**有效粒子**，这种粒子化分布才能很好的近似原始分布$p(x)$。
而衡量**有效粒子**数量$N_{eff}$的方式有很多，比如$N_{eff}=\frac{1}{max(w_i/W)}$，不过更常用的是如下的衡量方式：
$$
N_{eff}=\frac{1}{\sum_{i=1}^{n}{(w_i/W)^2}}
$$

- **结论4** ：设${X_1,X_2,X_3...,X_n}$是从分布$p(x)$中采样的、能充分反应分布$p(x)$的一组样本集，每个样本的权重分别为$\{w_1,w_2...w_n\}$，并设$\widehat{p}(x)=\sum_{i=1}^{n}{(w_i/W)\delta(x-X_i)}$，则当$N_{eff}$足够大时，有：$p(x)\sim \widehat{p}(x)$



## 通用粒子滤波器 (Generic Particle Filter)

### 粒子及其传递

我们可以用一堆带权重的样本点（粒子），来近似表达某一时刻的后验状态分布$p_{pos}(\boldsymbol{x}_{t-1})$：
比如 $(t-1)$时刻，后验分布近似表达为：$$p_{pos}(\boldsymbol{x}_{t-1})\sim \widehat{p}(\boldsymbol{x}_{t-1}) = \sum_{i=1}^{N}{\overline{w}_{t-1}^{(i)}}\delta(\boldsymbol{x}_{t-1}-\boldsymbol{x}_{t-1}^{(i)})$$
其中  $\boldsymbol{x}_{t-1}^{(i)}$ 就是 $(t-1)$时刻的一个粒子，$\overline{w}_{t-1}^{(i)}$ 是该粒子的权重。注意上式中的 $\overline{w}_{t-1}^{(i)}$ 应是归一化过的，即$\sum{\overline{w}_{t-1}^{(i)}}=1$；
当粒子足够多，即$N$足够大($N_{eff}$也足够大)时，这些粒子就能较准确地描述后验分布；

根据预备知识里的**结论2**，我们知道，有了这堆粒子，我们就能用蒙特卡罗方法近似求出任何关于$\boldsymbol{x}_{t-1}$的函数$g(\boldsymbol{x}_{t-1})$的期望；特别的，**如果令 $g(\boldsymbol{x}_{t-1})=\boldsymbol{x}_{t-1}$，我们求出的$E[g(\boldsymbol{x}_{t-1})]$就是$(t-1)$时刻的后验状态均值$\widehat{\boldsymbol{x}}_{t-1}$(滤波器输出的结果)**。
根据预备知识里的**结论3**，有了这堆粒子，我们就能用蒙特卡罗方法近似求出任何关于$\boldsymbol{x}_{t-1}$的函数$g(\boldsymbol{x}_{t-1})$与分布$p_{pos}(\boldsymbol{x}_{t-1})$的卷积。

如果将这些粒子传递到下一时刻，可近似得到$t$时刻的先验分布$p(\boldsymbol{x}_t)$：
$$
p(\boldsymbol{x}_{t}) = \int_{\Omega_{x_{t-1}}}p_{pos}(\boldsymbol{x}_{t-1}) p(\boldsymbol{x}_{t}|\boldsymbol{x}_{t-1})d\boldsymbol{x}_{t-1}\\
\approx \int_{\Omega_{x_{t-1}}}\widehat{p}(\boldsymbol{x}_{t-1}) p(\boldsymbol{x}_{t}|\boldsymbol{x}_{t-1})d\boldsymbol{x}_{t-1}=\sum_{i=1}^{N}{\overline{w}_{t-1}^{(i)}p(\boldsymbol{x}_{t}|\boldsymbol{x}_{t-1}^{(i)})}$$
上式中的近似利用了**结论2**和**结论3**中所体现的，在求积分类操作时，粒子化分布与原分布的近似性。

$t$时刻的后验分布$p_{pos}(\boldsymbol{x}_t)$为：
$$
p_{pos}(\boldsymbol{x}_t)=p(\boldsymbol{x}_t | \boldsymbol{y}_t) = \frac{p(\boldsymbol{x}_t)p(\boldsymbol{y}_t | \boldsymbol{x}_t)}{p(\boldsymbol{y}_t)}\approx \frac{\sum_{i=1}^{N}{\overline{w}_{t-1}^{(i)}p(\boldsymbol{x}_{t}|\boldsymbol{x}_{t-1}^{(i)})}p(\boldsymbol{y}_t | \boldsymbol{x}_t)}{p(\boldsymbol{y}_t)}=\\
\sum_{i=1}^{N}{\overline{w}_{t-1}^{(i)}\alpha p(\boldsymbol{x}_{t}|\boldsymbol{x}_{t-1}^{(i)})p(\boldsymbol{y}_t | \boldsymbol{x}_t)}
$$

在给定$\boldsymbol{y}_t$时，上式中的分母部分$p(\boldsymbol{y}_t)$是常量，因此上式中用 $\alpha$ 替换了$\frac{1}{p(\boldsymbol{y}_t)}$。
为方便表示定义：
$$\widetilde{p}(\boldsymbol{x}_{t}) =
\sum_{i=1}^{N}{\overline{w}_{t-1}^{(i)}\alpha p(\boldsymbol{x}_{t}|\boldsymbol{x}_{t-1}^{(i)})} p(\boldsymbol{y}_t | \boldsymbol{x}_t) $$
于是 $p_{pos}(\boldsymbol{x}_t)\approx \widetilde{p}(\boldsymbol{x}_{t})$。

但是$\widetilde{p}(\boldsymbol{x}_{t}) $的形式不利于状态分布在非线性变化(状态转移过程、观测过程)中继续向$(t+1)$时刻传递，我们希望将$t$时刻的后验分布同样以粒子的形式传递给$(t+1)$时刻。
所以，我们应该从$\widetilde{p}(\boldsymbol{x}_{t}) $中重新采样一些粒子。为了方便，我们保持粒子数为$N$，并将这$N$个新粒子传递给下一时刻；
$\widetilde{p}(\boldsymbol{x}_{t}) $是一个**有限混合分布**，它的第$i$个子分布是$[\alpha p(\boldsymbol{x}_{t}|\boldsymbol{x}_{t-1}^{(i)}) p(\boldsymbol{y}_t | \boldsymbol{x}_t)]$；
根据预备知识里提到的**结论0**和**结论4**，我们有：
$$\widetilde{p}(\boldsymbol{x}_{t}) \sim \widehat{p}(\boldsymbol{x}_{t}) = \sum_{i=1}^{N}{\overline{w}_{t-1}^{(i)}\delta(\boldsymbol{x}_{t}-\boldsymbol{x}_{t}^{(i)})}$$
其中，$\boldsymbol{x}_{t}^{(i)}$ 是从子分布$[\alpha p(\boldsymbol{x}_{t}|\boldsymbol{x}_{t-1}^{(i)}) p(\boldsymbol{y}_t | \boldsymbol{x}_t)]$中采样的一个粒子；
整体过程就是：
用$(t-1)$时刻的粒子，可以得到$t$时刻的近似后验分布$\widetilde{p}(\boldsymbol{x}_{t})$；再从$\widetilde{p}(\boldsymbol{x}_{t})$采样$N$个粒子，传递到$(t+1)$时刻。如此往复得到所有时刻的后验分布。
**靠粒子来传递分布，就是粒子滤波的核心思想**。

### 为什么需要重要性采样？

$[\alpha p(\boldsymbol{x}_{t}|\boldsymbol{x}_{t-1}^{(i)}) p(\boldsymbol{y}_t | \boldsymbol{x}_t)]$通常很难直接采样  It is often impossible to sample directly from the posterior density function.
而采用合适的 proposal 分布 $q_t^{(i)}(\boldsymbol{x}_{t})$ 后，采样就会容易很多。proposal 分布 $q_t^{(i)}$既有下标又有上标，表明不同时刻、不同粒子都有不同的 proposal 分布。
所以重要性采样主要用于**简化采样**。
The exact form of this distribution is a critical design issue, and is usually chosen **in order to facilitate easy sampling**.
此时，根据**结论1**和**结论4**，有

$$
p_{pos}(\boldsymbol{x}_{t}) \approx \widetilde{p}(\boldsymbol{x}_{t}) \sim \widehat{p}(\boldsymbol{x}_{t})= \sum_{i=1}^{N}{\frac{w_{t}^{(i)}}{W_t}\delta(\boldsymbol{x}_{t}-\widehat{\boldsymbol{x}}_{t}^{(i)})} = \sum_{i=1}^{N}{\widetilde{w}_{t}^{(i)}\delta(\boldsymbol{x}_{t}-\widehat{\boldsymbol{x}}_{t}^{(i)})}
$$

其中，$\widehat{\boldsymbol{x}}_{t}^{(i)}$ 是从$q_t^{(i)}(\boldsymbol{x}_{t})$中采样的一个粒子,
$w_{t}^{(i)}=\overline{w}_{t-1}^{(i)}\frac{\alpha p(\widehat{\boldsymbol{x}}_t^{(i)}|\boldsymbol{x}_{t-1}^{(i)})p(\boldsymbol{y}_t|\widehat{\boldsymbol{x}}_t^{(i)})}{q_t^{(i)}(\widehat{\boldsymbol{x}}_t^{(i)})}$是$t$时刻第$i$个粒子的权重（**结论1**）；常数$\alpha$不会影响归一化后的权重，所以我们可以忽略它，直接按
$$w_{t}^{(i)}=\overline{w}_{t-1}^{(i)}\frac{p(\widehat{\boldsymbol{x}}_t^{(i)}|\boldsymbol{x}_{t-1}^{(i)})p(\boldsymbol{y}_t|\widehat{\boldsymbol{x}}_t^{(i)})}{q_t^{(i)}(\widehat{\boldsymbol{x}}_t^{(i)})}$$
来计算权重；
$W_t=\sum_{i=1}^{N}{w_{t}^{(i)}}$是$t$时刻粒子总权重，
$\widetilde{w}_{t}^{(i)}=\frac{w_{t}^{(i)}}{W_t}$是$t$时刻第$i$个粒子的归一化权重。

### 重采样(Selection/Resampling) 

#### 重要性采样带来的问题：样本退化（Degeneracy problem）

我们之前提到过，在粒子化一个分布时，各粒子权重差异大，会导致**有效粒子数**$N_{eff}$减少，分布信息丢失。
而粒子滤波中重要性采样过程会引入各粒子的权重差异，而且随着时间增长，各粒子的权重差异还会被迅速放大。
 
要解决样本退化问题，可以有两个思路。

第一个思路，就是**选取尽可能好的 proposal 分布**：这样的 proposal 分布一般都会**把观测值(Likelyhood)考虑在内**，给出一个与实际分布$[p(\boldsymbol{x}_{t}|\boldsymbol{x}_{t-1}^{(i)})p(\boldsymbol{y}_t|\boldsymbol{x}_{t})]$相似度较高的推荐分布$q_t^{(i)}(\boldsymbol{x}_{t})$，使粒子尽可能向着(Likelyhood)区域移动，这样就可以使重要性权重经常在1附近或者不会差距太大，从而使得各粒子的权重始终保持较好的均衡性，保持 $N_{eff}$ 为一个足够大的数；但选择合适的proposal 分布通常不是件容易的事。粒子滤波的改进版本**无迹粒子滤波(UPF)**，用无迹卡尔曼滤波来为每个粒子计算proposal分布，就是利用的这个思路来防止样本退化，但随之而来的也是庞大的运算量：为每一个粒子跑一个UKF。

 
第二个思路，也是在实际中主要使用的，就是**重采样方法(Selection/Resampling)**。在下一小节中会着重介绍。

#### 重采样方法(Selection/Resampling)

解决粒子权重失衡问题，有一种更直接的方法，就是对"重要性采样"得到的带权重粒子$\{\widehat{\boldsymbol{x}}_t^{(i)},\widetilde{w}_t^{(i)}|i=1:N\}$，进行一次重采样 (每个粒子被再次采到的概率等于它的权重)，得到$\{\widetilde{\boldsymbol{x}}_t^{(i)},\overline{w}_t^{(i)}=(1/N)|i=1:N\}$，使得重采样后的粒子$\widetilde{\boldsymbol{x}}_t^{(i)}$都有相同的权重$\overline{w}_t^{(i)}=1/N$。 
重采样步骤的本质，是从离散分布 $\widehat{p}(\boldsymbol{x}_{t}) = \sum_{i=1}^{N}{\widetilde{w}_{t}^{(i)}\delta(\boldsymbol{x}_{t}-\widehat{\boldsymbol{x}}_{t}^{(i)})}$ 中采样$N$个新粒子。
其实现非常简单，就是按各粒子权重计算阶梯CDF函数，然后用CDF法采样即可。见下图。这样的重采样过程，倾向于丢弃( Eliminate)权重非常小的粒子，复制多份（Multiply）权重显著的粒子。这种方法操作简单，又能得到一组与原粒子集$\{\widehat{\boldsymbol{x}}_t^{(i)},\widetilde{w}_t^{(i)}|i=1:N\}$分布相同的等权重粒子集$\{\widetilde{\boldsymbol{x}}_t^{(i)},\overline{w}_t^{(i)}=(1/N)|i=1:N\}$，所以重采样(Selection/Resampling) 在通用粒子滤波中已经成为一个相对固定的步骤。
![](https://github.com/NewThinker-Jeffrey/Figures/raw/main/figures/2b22e76d3b90c91dfc7e06f41ef62b9a.png)
得到新的等权重粒子集$\{\widetilde{\boldsymbol{x}}_t^{(i)}|i=1:N\}$后，我们就可以用一个新的分布$\overline{p}(\boldsymbol{x}_{t})$来近似$t$时刻的后验状态分布：
$$
p_{pos}(\boldsymbol{x}_{t})\sim \overline{p}(\boldsymbol{x}_{t})=\sum_{i=1}^{N}{\overline{w}_{t}^{(i)}\delta(\boldsymbol{x}_{t}-\widetilde{\boldsymbol{x}}_{t}^{(i)})}=\sum_{i=1}^{N}{(1/N)\delta(\boldsymbol{x}_{t}-\widetilde{\boldsymbol{x}}_{t}^{(i)})}
$$
并把粒子集 $\{\widetilde{\boldsymbol{x}}_t^{(i)}|i=1:N\}$ 传递到$(t+1)$时刻。


### 通用粒子滤波算法流程
到这里，我们已经说完了通用粒子滤波算法中的几个主要环节。
下面总结一下通用粒子滤波算法的流程。
算法开始前，要先根据经验、采样友好度，选择先验分布$p(\boldsymbol{x}_0)$。

1. 时刻$t=0$，采样初始粒子： 
 - $\text{for }i=0,1,2....,N$，采样$\boldsymbol{x}_0^{(i)}\sim p(\boldsymbol{x}_0)$，设置权重$\overline{w}_0^{(i)}=1/N$

2. $t=t+1$;
3. 重要性采样：
 - 从 proposal 分布中采样并计算重要性权重：
$\text{for }i=0,1,2....,N$，采样 $\widehat{\boldsymbol{x}}_{t}^{(i)}\sim q_t^{(i)}(\boldsymbol{x}_{t})$，计算权重$w_t^{(i)}=\overline{w}_{t-1}^{(i)}\frac{p(\widehat{\boldsymbol{x}}_{t}^{(i)}|\boldsymbol{x}_{t-1}^{(i)})p(\boldsymbol{y}_t|\widehat{\boldsymbol{x}}_{t}^{(i)})}{q_t^{(i)}(\boldsymbol{x}_{t})}$
 - 归一化权重：
$\text{for }i=0,1,2....,N$， 计算 $\widetilde{w}_t^{(i)}=w_t^{(i)}/(\sum_i^N{w_t^{(i)}})$.

4. 重采样：
从离散分布 $\widehat{p}(\boldsymbol{x}_{t}) = \sum_{i=1}^{N}{\widetilde{w}_{t}^{(i)}\delta(\boldsymbol{x}_{t}-\widehat{\boldsymbol{x}}_{t}^{(i)})}$ 中采样$N$个新粒子，每个新粒子权重为$(1/N)$，得到$\{\widetilde{\boldsymbol{x}}_{t}^{(i)}, \overline{w}_{t}^{(i)}=(1/N)|i=1,2,3...N\}$

5. $\text{for }i=0,1,2....,N$，$\boldsymbol{x}_{t}^{(i)}=\widetilde{\boldsymbol{x}}_{t}^{(i)}$
6. 输出结果：
$$E[g(\boldsymbol{x}_{t})]=(1/N)\sum_{i=1}^{N}g(\boldsymbol{x}_{t}^{(i)})$$
返回步骤 2 处理下一时刻

#### 以状态转移分布为proposal分布的粒子滤波

很多情况下，人们会选择状态转移分布作为proposal分布，即选择$q_t^{(i)}(\boldsymbol{x}_{t})=p(\boldsymbol{x}_{t}|\boldsymbol{x}_{t-1}^{(i)})$，这样实现起来比较简单，也是比较常用的方法。
如果$t$时刻的状态转移分布$p(\boldsymbol{x}_{t}|\boldsymbol{x}_{t-1}^{(i)})$可以直接采样，我们就可以把上面"通用粒子滤波流程"中的第3步简化如下。
1. ...
2. ...
3. 重要性采样：
 - 从 proposal 分布中采样并计算重要性权重：
$\text{for }i=0,1,2....,N$，采样 $\widehat{\boldsymbol{x}}_{t}^{(i)}\sim p(\boldsymbol{x}_{t}|\boldsymbol{x}_{t-1}^{(i)})$，计算权重$w_t^{(i)}=\overline{w}_{t-1}^{(i)}p(\boldsymbol{y}_t|\widehat{\boldsymbol{x}}_{t}^{(i)})$
 - 归一化权重：
$\text{for }i=0,1,2....,N$， 计算 $\widetilde{w}_t^{(i)}=w_t^{(i)}/(\sum_i^N{w_t^{(i)}})$.

4. ...
5. ...
6. ...


---------------------------------------


# 深入篇

前面的部分已经把粒子滤波的主要思想、重要步骤的推导以及实现流程都介绍过了，只是想初步了解或实现最简单的粒子滤波器的话，读完前面的部分就已经足够。如果希望了解粒子滤波的一些提高方法，比如用$MCMC move$减弱样本贫化、更好的$proposal$分布的设计等，则需要对粒子滤波有更深入的理解。
本篇中某些小节读起来可能比较艰难，如果需要只需大致浏览一遍，细节部分选择性阅读即可。

## 预备知识 (2) - 马尔科夫链(Markov Chain) 与 MCMC采样

在粒子滤波算法的优化中，为了减少重采样(Selection/Resampling)引起的样本贫化现象，在重采样过程结束后会加入一步 MCMC move ，只有这个步骤中，会用到本节的部分内容。
如果不想了解 MCMC move，可以略过本节不看。

### *马尔科夫链及其收敛定理

**马尔科夫 (Markov) 过程**：若$X_{k+1}$ 和 $X_k$ 分别是 $(k+1)$ 时刻和 $k$时刻的状态，且$X_{k+1}$ 的分布只依赖于$X_k$，而与更早时刻的状态无关。这样的过程被称为马尔科夫过程。

关于马尔科夫链的简介可以看这篇博文中的第6节：  http://www.cnblogs.com/xbinworld/p/4266146.html
上面的博文中用简单的例子使读者能直观地明白什么是马尔科夫链，本文就不再重复这些介绍。本文的主要目的是说明一些技术性问题，为理解粒子滤波中的一些技术细节打下理论基础。
文中提到了**马氏链的收敛定理**： 无论初始分布$\pi_0$是什么，按照马氏链的概率转移矩阵$P$演化一定次数后，最终都趋于一个稳态分布$\pi$。
当然，这个定理只对满足“连通性”和“非周期性”的马氏链有效。详见下图：
![](https://github.com/NewThinker-Jeffrey/Figures/raw/main/figures/f41178f40815981adae9eae0b828859d.png)

> Proof : (*理解上面的结论就足够了，证明有些繁琐，可以略过*)
> 首先，$P$是概率转移矩阵，因此满足：
> - 概率转移矩阵 **$P$ 的每个元素都是非负的**：$P_{ij}$代表从状态$i$转移到状态$j$的概率，概率都是非负的；
> - **$P$ 每行的元素之和是 1**：第 $i$ 行的元素之和$\sum_j{P_{ij}}$，代表从状态$i$转移到所有状态(包括状态$i$自身)的总概率，总概率是1；
>
>  由于概率转移矩阵乘以另一个概率转移矩阵，得到还是一个概率转移矩阵，因此$P^n$也是概率转移矩阵，即**$P^n$也满足上面两条**。
我们首先讨论一种比较简单的情况：**假设$P$ 的所有元素都是正的**.
由于 $P$ 的所有元素都是正的，根据**Perron-Frobenius 定理**(可以先忽略这个陌生的名字，直接看它的结论)，我们有如下结论：
> -  $P$ 存在一个**正的实特征值$\lambda_1$**，且存在与之对应的**正实特征向量**(每个元素都是正数的特征向量)；
> -  $\lambda_1$是$P$的**单重特征值**，即$\lambda_1$是$[det(\lambda \boldsymbol{I}-P)=0]$的单重特征根；
> -  在$P$所有的特征值$\{\lambda_1, \lambda_2, \lambda_3...\}$中，**$\lambda_1$是绝对值最大的特征值**：即若$\{\lambda_1, \lambda_2, \lambda_3...\}$已**按绝对值大小排序**，则有$|\lambda_1|>|\lambda_2|\ge|\lambda_3|\ge|\lambda_4|...$，注意第一个是“大于”，不是“大于等于”。
> 注意除$\lambda_1$外，**其他特征值都可能是复数**。
$P$的约当标准形式$J$可写为：
$$J=\left[\begin{matrix} 
\lambda_1&0&0&...\\
0&\lambda_2&0&...\\
0&0&\lambda_3&...\\
...&...&...&...\\
\end{matrix}\right]=
\lambda_1\left[\begin{matrix} 
1&0&0&...\\
0&\beta_2&0&...\\
0&0&\beta_3&...\\
...&...&...&...\\
\end{matrix}\right]$$
其中$\beta_i=\lambda_i/\lambda_1$，且$|\beta_i|<1$。
$P$可对角化为：$P=QJQ^{-1}$，因此
$$
P^n=(QJQ^{-1})(QJQ^{-1})...(QJQ^{-1})=QJ^nQ^{-1}=\\
Q\lambda_1^n\left[\begin{matrix} 
1&0&0&...\\
0&\beta_2^n&0&...\\
0&0&\beta_3^n&...\\
...&...&...&...\\
\end{matrix}\right]
Q^{-1}
$$
由于$|\beta_i|<1$，上式中的对角阵(除左上角的1外)是**指数收敛**的，而**这也正是马尔科夫链的收敛规律**，收敛速度取决于**绝对值第二大**的特征值$\lambda_2$与实特征值$\lambda_1$的比，即可以认为收敛速率因子为： $|\beta_2|=|\lambda_2/\lambda_1|$。
当$n$趋向无穷时，所有的$\beta_i^n\rightarrow 0$，我们得到极限：
$$
\lim_{n\rightarrow \infty}P^n=Q\lambda_1^n\left[\begin{matrix} 
1&0&0&...\\
0&0&0&...\\
0&0&0&...\\
...&...&...&...\\
\end{matrix}\right] \\
Q^{-1}=\lambda_1^n\left[\begin{matrix} 
Q_{11}Q^{-1}_{11}&Q_{11}Q^{-1}_{12}&Q_{11}Q^{-1}_{13}&...\\
Q_{21}Q^{-1}_{11}&Q_{21}Q^{-1}_{12}&Q_{21}Q^{-1}_{13}&...\\
Q_{31}Q^{-1}_{11}&Q_{31}Q^{-1}_{12}&Q_{31}Q^{-1}_{13}&...\\
...&...&...&...\\
\end{matrix}\right]=\lambda_1^n\left[\begin{matrix} 
Q_{11}Q^{-1}_{1:}&\\
Q_{21}Q^{-1}_{1:}&\\
Q_{31}Q^{-1}_{1:}&\\
...&\\
\end{matrix}\right]
$$
其中$Q^{-1}_{1:}$代表$Q^{-1}$的第一行。
由于$P^n$每一行的和都应是1，即 
$$
\lambda_1^nQ_{11}\times sum(Q^{-1}_{1:})=1\\
\lambda_1^nQ_{21}\times sum(Q^{-1}_{1:})=1\\
\lambda_1^nQ_{31}\times sum(Q^{-1}_{1:})=1\\
...$$
因此 $Q_{11}=Q_{21}=Q_{31}=...$。即$Q$的第1列都是相同的数，记为$q$；再设$\pi=\lambda_1^nqQ^{-1}_{1:}$，则有
$$
\lim_{n\rightarrow \infty}P^n=\left[\begin{matrix} 
\lambda_1^nqQ^{-1}_{1:}&\\
\lambda_1^nqQ^{-1}_{1:}&\\
\lambda_1^nqQ^{-1}_{1:}&\\
...&\\
\end{matrix}\right]=\left[\begin{matrix} 
\pi&\\
\pi&\\
\pi&\\
...&\\
\end{matrix}\right]
$$
>
> (由于$P^n$每一行的元素都为正，且每一行的和都是1，所以$\pi$的所有元素都为正，且和为1。$\pi$不为0，且有限)
考虑到$\lambda_1>0$，为使当$(n\rightarrow\infty)$时 $\pi=\lambda_1^nqQ^{-1}_{1:}$ 有限且不为0，$\lambda_1$只能是 1，$\lambda_1=1$。
$\pi=\pi P$ 的解是对应$\lambda_1=1$ 的特征向量，而由于$\lambda_1$是单重特征值，所以与之对应的特征向量都可以表达成$c\pi$(都是与$\pi$共线的向量)，这样的向量中只有一个是可以作为概率分布的（各元素之和等于1）。因此$\pi$也是$\pi=\pi P$ 的唯一非负解。
到此，主要的证明过程完毕。
上面只讨论了当状态转移矩阵是 **正矩阵** 的情况，但其实，对于$P$是 **素矩阵(primitive matrix)** 的情况下，上面结论同样成立。
**素矩阵** ： 对于方阵$A$，如果存在自然数$k$使得$A^k$是正矩阵，则$A$是素矩阵。
如果$P$是素矩阵，我们可以找到矩阵 $R=P^k$使得$R$是一个正矩阵，这样$R$就是一个正的概率转移矩阵，$R$满足上面的结论，即 $(n\rightarrow \infty)$ 时 $R^n$ 必收敛于某一个每行都相等的矩阵$R_{\pi}=\left[\begin{matrix}\pi_r&\\\pi_r&\\\pi_r&\\...\end{matrix}\right]$，根据概率转移阵$P$每行元素之和为1的特点，$PR_{\pi}=R_{\pi}$。因此$n\rightarrow\infty$时 $P^n$也收敛于$R_{\pi}$。之前针对正概率转移矩阵的结论同样适用于素矩阵。
而在马氏链定理的假设中已经提到，“任何两个状态是联通的”，这保证了概率转移矩阵$P$是 **非负不可约矩阵(non-negative irreducible matrix)** ：如果$n\times n$的方阵$A$，对于任意的 $0<i,j<n$ ，存在自然数 $k_{ij}$ 使得 $(A^{k_{ij}})_{ij}>0$ ，则$A$是非负不可约矩阵；
而“非周期马氏链”又限定了$P$只能是素矩阵(primitive matrix)。
BTW, **非负不可约矩阵(non-negative irreducible matrix)**包含两个子类：一个是**素矩阵(primitive matrix)**，还有一个是**循环阵**。后者对应周期性的马尔科夫链。
- 考虑这样一个马尔科夫链：状态空间包含$\{A,B,C\}$三个状态；初始分布为$\{A,B,C\}=\{1,0,0\}$；每个时刻，A全部(以概率1)转移到B，B全部转移到C，C全部转移回A，对应的概率转移矩阵就是$\left[\begin{matrix}0&1&0\\0&0&1\\1&0&0\end{matrix}\right]$。对于这个马氏链，可以发现并不存在稳态分布，而是A,B,C三个状态周期性的出现。而且可以看出它的概率转移矩阵是一个循环阵：它每一行的元素都是上一行各元素依次右移一个位置得到的结果。

> 这里的证明借助了 **Perron-Frobenius 定理** 及其扩展，当然 Perron-Frobenius 定理本身的证明也是比较繁琐的，想了解其证明过程可以参考下面这本书的 Chapter 8（最后一章）：
*《Matrix Analysis and Applied Linear Algebra》Carl D. Meyer著(2001) *
如果找不到这本书，下面这两个ppt里也有详尽的证明：
**正矩阵**的 Perron-Frobenius 定理的证明 (Proof of the Perron-Frobenius Theorem) ：   
http://math.arizona.edu/~dshahar/PerronFrobeniusTheorem.pdf

**非负不可约矩阵 (irreducible matrix)** 的 扩展Perron-Frobenius 定理的证明：
http://www.math.harvard.edu/library/sternberg/slides/1180912pf.pdf
Wiki上关于Perron-Frobenius 定理及其扩展的简介：
https://en.wikipedia.org/wiki/Perron%E2%80%93Frobenius_theorem#Non-negative_matrices_2

### *马氏链的遍历性(ergodicity)

我们上一节只介绍了**状态数量有限或可数**(状态空间是有限集或可数集)的马氏链；
对于**状态空间是不可数集**的连续状态马氏链，收敛定理同样适用： 满足遍历性(ergodicity)的马氏链，存在稳态分布。
这里提到一个新名词，*遍历性(ergodicity)*。字面意义上可以理解为，任意的初始分布经过这样的马氏链转移一定次数后，其最终分布可以遍历状态空间中所有的状态 (所有状态的概率或概率密度都大于0)。当然，**这并不是遍历性(ergodicity)的准确定义**。
**我们只需要知道：满足遍历性(ergodicity)的马氏链，会存在稳态分布，且从任意的初始分布出发，通过多次转移都能收敛到稳态分布**；

- 对于有限状态马氏链，“任意两个状态互相连通(irreducible)、且非周期(aperiodic)”的马氏链，都是遍历性(ergodic)的；这样的马氏链，我们称它对应的状态转移矩阵$P$也是遍历性(ergodicity)的。
- 对于连续状态马氏链，如果满足“各状态互相连通(irreducible)、非周期(aperiodic)”，通常也是遍历性(ergodic)的——还有一个条件叫“正常返(positive recurrence)”，但不用太过纠结这些概念，掌握粒子滤波并不需要非常深入地了解马氏链；对于连续状态空间，我们还要改变一些说法，比如不能再说某个状态的“概率”是多少，而只能说概率密度；而且连续状态的马尔科夫链不存在“概率转移矩阵”，取而代之的是“概率转移函数(kernel)”，比如用$q(i,j)$代表从状态$i$转移到状态$j$的概率密度，$q$就是概率转移 kernel；如果一个马氏链是遍历性(ergodic)的，我们称它的kernel 即$q$也是遍历性的。

> 关于遍历性(ergodicity)的的一些正式定义：（可以略过，不必细读，只做参考）
> - 对时间的平均等于对状态空间的平均：https://en.wikipedia.org/wiki/Ergodicity
![](https://github.com/NewThinker-Jeffrey/Figures/raw/main/figures/4b9b0b9e28e26e034b3bb34f744b15e5.png)
>
> - 对于马尔科夫链的遍历性，可以理解为：
遍历性(ergodic) = 不可约(irreducible) + 非周期(aperiodic) + 正常返(positive recurrent)
https://en.wikipedia.org/wiki/Markov_chain#Ergodicity
![](https://github.com/NewThinker-Jeffrey/Figures/raw/main/figures/1cdfc1e862a6067b1491f43995853b94.png)


### 马氏链的细致平稳条件与 MCMC 采样法简介

考虑一个转移概率矩阵为$Q$、有限状态的ergodic马氏链，稳态分布为$\pi$。
在0时刻，我们从任意一个状态$X_0$开始，沿着该马氏链进行转移，这相当于我们的初始分布是$\pi_0(X)=\delta(X-X_0)$，即状态$X_0$的概率为1，其他状态概率为0；
时刻 1，状态由$X_0$按照转移概率随机转移到$X_1$，则$X_1$的分布为 $\pi_1=\pi_0Q$；
时刻 2，状态由$X_1$按照转移概率随机转移到$X_2$，则$X_2$的分布为 $\pi_2=\pi_1Q=\pi_0Q^2$；
......
时刻 n，状态由$X_{n-1}$按照转移概率随机转移到$X_n$，则$X_n$的分布为 $\pi_n=\pi_0Q^n$；
...

假如在时刻$m$的时候，$\pi_m$就几乎收敛到了稳态分布$\pi$，那么我们在$m$时刻以后获得的样本$\{X_m, X_{m+1}, X_{m+2}....\}$的分布就都是稳态分布$\pi$。
这意味着，$\{X_m, X_{m+1}, X_{m+2}....\}$相当于是从分布$\pi$中采集的一组样本！
> 这正好印证了前面提到的 ergodicity 的标准定义中的一句话 : 对时间的平均等于对状态空间的平均。$\{X_m, X_{m+1}, X_{m+2}....\}$是来自于随机过程的**不同时间**的样本，而他们的分布正好等于状态空间中样本的分布。时间上的分布 = 状态空间上的分布。

而且，由于马氏链是指数收敛的，$m$通常不会很大，马氏链开始转移后，我们不用等太久就可以得到稳态分布的样本。比如我们按照马氏链转移获得了${X_1, X_2, X_3....X_{1000}}$共$1000$个样本，通常我们只需要删去前面的几十个就可以得到符合稳态分布$\pi$的一组样本了。

虽然上面的例子针对的是有限状态的马尔科夫链，不过同理，我们也可以通过在一个连续状态的ergodic马尔科夫链中随机转移，获得符合其稳态分布$p(x)$的一组样本(连续状态马氏链的稳态分布通常是一个连续分布)。

这启发了我们一种新的采样方法：为实现对某个目标分布 $p(x)$ 采样，可**先构造一个以$p(x)$为稳态分布且 ergodic 的马尔科夫链，然后在该马尔科夫链中随机转移来获得符合$p(x)$的样本**。
这种采样方法就叫做 **MCMC采样法 (Markov Chain Monte Carlo)**。

那么现在的问题是，如何构造一个以$p(x)$为稳态分布的马尔可夫链呢？
马尔可夫链的稳态分布取决于其转移概率矩阵，或者转移概率kernel，所以问题变成我们怎样设计这样的 kernel ?
下面即将提到的**细致平稳条件**就是很好的 kernel 设计准则。

- **定义**：可逆(reversible)马尔科夫链与细致平稳条件**
对于一个马氏链，如果存在一个分布 $p$，对于状态空间中的任意两个状态 $(i,j)$，满足：
$$p(i)q(i,j)=p(j)q(j,i)$$
称该马氏链是**可逆(reversible)马尔科夫链**，上面的条件则称为**细致平稳条件(detailed balance condition)**。
其中，$p(i),p(j)$分别代表状态$i,j$在分布$p$中的概率或概率密度，$q(i,j)$代表从状态$i$转移到状态$j$即$(i\rightarrow j)$的概率或概率密度，$q(j,i)$代表$(j\rightarrow i)$的概率或概率密度。
对于离散时间、有限状态的马氏链，若其状态转移矩阵是$Q$，则$q(i,j)=Q_{ij},q(j,i)=Q_{ji}$；
对于离散时间、连续状态的马氏链，$q(i,j)$被称为该马氏链的转移概率函数(或kernel)，$q(i,j)$和$p(i)$代表的都是概率密度，不再是概率。
**如果一个可逆马氏链同时也满足遍历性，则$p$是该马氏链的唯一稳态分布**。

细致平稳条件可以理解为，从状态$i$转移到状态$j$的概率量，等于从状态$j$转移回状态$i$的概率量。
这意味着，任何两个状态之间的概率转移会互相抵消，从而使得下一时刻的状态分布，与当前时刻始终保持一致，即达到稳态分布。
因此，在设计 kernel 的时候，我们只要保证选择的 kernel **$q(x_i, x_j)$与目标分布$p(x)$满足细致平稳条件，且$q(x_i, x_j)$是遍历性的，就可以保证我们构造的马氏链能收敛到$p(x)$**。
接下来我们会介绍两种具体的MCMC采样法。这两种方法的差异性只在于选取了不同的$kernel$。

### Metropolis-Hastings 采样法（MH 采样法）

我们下面介绍一种最常见的 MCMC 采样法： Metropolis-Hastings 采样法。
Metropolis 也是第一个想到用 MCMC 方法来采样的人。

#### MH 采样法原理

假设我们要采样的目标分布为$p(x)$。首先，我们先根据经验选择一个方便采样的 kernel ：$q(x_i, q_j)$。
我们当然不能保证$q$和$p$满足细致平稳条件，即通常：$p(x_i)q(x_i,x_j)\not= p(x_j)q(x_j,x_i)$。
但是，我们可以选择一个$\alpha(x_i,x_j)$和$\alpha(x_j,x_i)$ ，使得 $p(x_i)q(x_i,x_j)\alpha(x_i,x_j)= p(x_j)q(x_j,x_i)\alpha(x_j,x_i)$。
怎么选呢？可能有点耍赖皮，但是合理：$\alpha(x_i,x_j)=p(x_j)q(x_j,x_i)$，$\alpha(x_j,x_i)=p(x_i)q(x_i,x_j)$。这样上面等式两边就一定相等了。
而新出现的$\alpha$，叫做采纳率/接受率。即每一时刻，我们以概率$\alpha$来接受一个转移：比如设$X_n$是$n$时刻的状态，那么在向$(n+1)$时刻转移时，我们先从$q(X_n, x)$中采样一个$X$，再从$[0,1]$均匀分布中抽取一个随机数$\mu$。如果$\mu > \alpha(X_n, X)$，则接受转移，设置$X_{n+1}=X$；否则，不接受转移，$X_{n+1}=X_n$。
这样看来，我们的新采样方法已经可以有效的工作了，但有两点缺憾需要弥补：
- $\alpha(X_n, X)$ 通常可能会变得很小比如$0.01$，这会导致转移率很低，状态长时间停留在某个点上，导致马氏链收敛慢；
- 不排除有些地方 $\alpha(X_n, X)$ 可能会超过 1，接受率大于 1 导致我们的采样结果出现偏差 (就像“接受/拒绝采样"方法中，接受率大于1的时候一样)。

因此，我们要设计新的接受率函数$\alpha'(x_i,x_j)$，使得在满足细致平稳条件的前提下，接受率尽可能大（加快马氏链收敛），但又不超过 1。
重新观察等式， $p(x_i)q(x_i,x_j)\alpha(x_i,x_j)= p(x_j)q(x_j,x_i)\alpha(x_j,x_i)$，它可以有两个变形：
$$
p(x_i)q(x_i,x_j)\times 1=p(x_j)q(x_j,x_i)\times \frac{\alpha(x_j,x_i)}{\alpha(x_i,x_j)}\\
p(x_i)q(x_i,x_j)\times \frac{\alpha(x_i,x_j)}{\alpha(x_j,x_i)}=p(x_j)q(x_j,x_i)\times 1
$$
而$\frac{\alpha(x_j,x_i)}{\alpha(x_i,x_j)}$和$\frac{\alpha(x_i,x_j)}{\alpha(x_j,x_i)}$中必然有一个是小于等于1的。
因此我们可以定义：$$\alpha'(x_i,x_j)=\min \left[1, \frac{\alpha(x_i,x_j)}{\alpha(x_j,x_i)}\right]$$
与之对称的：$\alpha'(x_j,x_i)=\min \left[1, \frac{\alpha(x_j,x_i)}{\alpha(x_i,x_j)}\right]$
这样我们有： $p(x_i)q(x_i,x_j)\alpha'(x_i,x_j)= p(x_j)q(x_j,x_i)\alpha'(x_j,x_i)$。
再定义
$$q'(x_i,x_j)=q(x_i,x_j)\alpha'(x_i,x_j)+c\delta(x_j-x_i)$$
这样就构造出了一个能与$p(x)$满足细致平稳条件的新kernel : $q'$。
因此，我们可以从任意一点$X_0$开始，按照转移概率kernel $q'$进行随机转移：
- 在时刻$0$，任意选定一个初始状态$X_0$；
- 在时刻$1$，从关于$x$的分布 $q'(X_0, x)$中随机采样一个点$x=X$，并转移：$X_{1}=X$；
- 在时刻$2$，从关于$x$的分布 $q'(X_1, x)$中随机采样一个点$x=X$，并转移：$X_{2}=X$；
- ...
- 在时刻$k$，从关于$x$的分布 $q'(X_{k-1}, x)$中随机采样一个点$x=X$，并转移：$X_{k}=X$；
- ...

这样转移一定次数后，就可以得到一系列满足分布$p(x)$的样本。

> 注意$q'(x_i,x_j)$的定义式的等号右边额外加了一个系数为$c$的$\delta$函数。
若 $x_i \not= x_j$，我们有 $q'(x_i,x_j)=q(x_i,x_j)\alpha'(x_i,x_j)$；
我们不能直接将 $q'(x_i,x_j)$ 定义为$q(x_i,x_j)\alpha'(x_i,x_j)$，是考虑到$q'(x_i,x_j)$与$q(x_i,x_j)$一样都应该是关于$x_j$的一个概率分布函数，即$\int_{\Omega}q'(x_i,x_j)dx_j=\int_{\Omega}q(x_i,x_j)dx_j=1$。
而$\alpha'(x_i,x_j)\le 1$，且很多情况下是$\alpha'(x_i,x_j) < 1$，这样的$x_j$点集($\{x_j|\alpha'(x_i,x_j) < 1\}$)通常有非0的测度，因此：$\int_{\Omega}q(x_i,x_j)\alpha'(x_i,x_j)dx_j<\int_{\Omega}q(x_i,x_j)dx_j=1$。
即$q(x_i,x_j)\alpha'(x_i,x_j)$ 不能作为 $x_j$的一个分布函数，也就不能被直接当做一个 kernel，需要稍加调整。
考虑到当$x_j = x_i$时，有 $\begin{cases}q'(x_i,x_j)=q'(x_i,x_i)\\p(x_i)=p(x_j)\end{cases}$，此时，无论$q'(x_i,x_i)$的值 (从$x_i$转移到其自身的概率密度) 定义为多少，细致平稳条件始终成立。因此我们可以随意设定$q'(x_i,x_i)$的值来使$q'(x_i,x_j)$满足一个分布函数的特征。所以我们定义
$$q'(x_i,x_j)=q(x_i,x_j)\alpha'(x_i,x_j)+c\delta(x_j-x_i)$$
其中 $c=\int_{\Omega}q(x_i,x_j)dx_j-\int_{\Omega}q(x_i,x_j)\alpha'(x_i,x_j)dx_j$。
这样$q'(x_i, x_j)$就是$x_j$的一个分布函数了，$\int_{\Omega}q'(x_i,x_j)dx_j=1$。
此时相当于$q'(x_i,x_j)=\begin{cases}q(x_i,x_j)\alpha'(x_i,x_j)&\text{for  }x_j\not= x_i\\\infty=c\delta(x_j-x_i)&\text{for  }x_j= x_i\end{cases}$


那**怎样从分布$q'(X_k,x)$中采样**呢？虽然我们最初选择的kernel $q(X_k,x)$比较容易采样，但$q'(X_k,x)$已经被我们"改造"成了一个很复杂的分布，从而并不能直接采样。
考虑到当$x\not= X_k$时，我们始终有 $q'(X_k,x)=q(X_k,x)\alpha'(X_k,x)\le q(X_k,x)$，我们可以类似于"接受/拒绝 采样"的方法来对$q'(X_k,x)$采样，$\alpha'$依然是接受率：
- 首先，从 $q(X_k,x)$ 中采样一个点$X$；
- 再从$[0,1]$均匀分布中得到一个随机数$\mu$；
- 如果$\mu \le \alpha'(X_k,X)$，即$\mu \le \min \left[1, \frac{\alpha(X_k,X)}{\alpha(X,X_k)}\right]$，则接受$X$，$X_{k+1}=X$(接受转移)；否则，拒绝$X$，认为抽到的是$X_k$，并设置$X_{k+1}=X_k$(拒绝转移)

> 下图中，蓝色曲线代表 $q(X_k,x)$ ，红色曲线代表 $q'(X_k,x)$；
在很多区域，蓝色曲线和红色曲线是重叠的，这些地方$\alpha'(X_k,x)=1$;
也有些区域，红色曲线比蓝色曲线低，这些地方$\alpha'(X_k,x)<1$，且在图中以"缺失块"标记；
在$x=X_k$处，红色曲线存在一个脉冲，这是$c\delta(x-X_k)$的作用；
其中$c$就是图中所有"缺失块"区域的面积之和；
脉冲区域的面积也等于图中"缺失块"区域的面积之和；
前述对$q'(X_k,x)$的采样过程，其本质，其实是在蓝色曲线与$x$轴围成的区域中均匀采点，然后将落在"缺失块"中的点(被拒绝转移的点) 都移到脉冲区域中；这样当采到"缺失块"中的点时，即$\mu > \min \left[1, \frac{\alpha(X_k,X)}{\alpha(X,X_k)}\right]$时，我们认为是采到的是$X_k$。
![](https://github.com/NewThinker-Jeffrey/Figures/raw/main/figures/1a856b0a9e3360beeb330455b368b359.png)


#### MH 采样法的完整流程

采样开始前，要选定参考 kernel : $q$。$q(x_i,x_j)$表示状态从$x_i$转移到$x_j$的概率(密度)。
$q$ 必须是$ergodic$的。
MH 采样法步骤：
1.  设时刻$k=0$，随意选定初始状态$X_0$；
2.  从关于$x$的分布 $q(X_{k},x)$ 中抽样，得到$X$：采样 $X\sim q(X_{k},x)$
3. 从$[0,1]$均匀分布中抽取随机数 $\mu$：采样 $\mu\sim \mathcal{U}_{[0,1]}$；
4. - 如果$\mu \le \min \left[1, \frac{p(X)q(X,X_{k})}{p(X_{k})q(X_{k},X)}\right]$，接受转移，$X_{k+1}=X$;
 - 否则，拒绝转移，$X_{k+1}=X_{k}$;
5.  $k=k+1$;6.  如果$k$超过指定样本数量，采样完成，退出；否则，返回步骤2继续；


### Gibbs 采样法

#### Gibbs 采样法原理

MH 采样法无法避免转移接受率低的情况。
对于高维分布，如果**每个维上的条件概率分布都是容易采样的**，就可以使用一种接受率为 1 的高效采样方法了，这就是 Gibbs 采样法。
以三维分布举例说明。
设状态$x$为随机向量$x=\left[\begin{matrix}x_1\\x_2\\x_3\end{matrix}\right]$。
目标分布$p(x)=p(x_1,x_2,x_3)$是随机变量$x_1$、$x_2$和$x_3$的联合分布。
如果
- 对于任意的$x_1,x_2$，条件概率$p(x_3|x_1,x_2)$是可采样的
- 对于任意的$x_2,x_3$，条件概率$p(x_1|x_2,x_3)$是可采样的
- 对于任意的$x_3,x_1$，条件概率$p(x_2|x_3,x_1)$是可采样的


就可以用使用Gibbs方法采样了。
设$A=\left[\begin{matrix}x_{1a}\\x_{2a}\\x_{3a}\end{matrix}\right], B=\left[\begin{matrix}x_{1b}\\x_{2b}\\x_{3b}\end{matrix}\right]$是状态空间的两个点，根据贝叶斯公式，我们有
$$
p(A)=p(x_{1a},x_{2a},x_{3a})=p(x_1A|x_{2a},x_{3a})p(x_{2a},x_{3a})\\
p(B)=p(x_{1b},x_{2b},x_{3b})=p(x_1B|x_{2b},x_{3b})p(x_{2b},x_{3b})
$$
若$A,B$具有相同的$x_2$和$x_3$，即$\begin{cases}x_{2a}=x_{2b}=x_2^*\\x_{3a}=x_{3b}=x_3^*\end{cases}$，此时
$$
\begin{cases}
p(B)=p(x_{1b}|x_2^*,x_3^*)p(x_2^*,x_3^*)\\
p(A)=p(x_{1a}|x_2^*,x_3^*)p(x_2^*,x_3^*)
\end{cases}\Rightarrow p(B)p(x_{1a}|x_2^*,x_3^*)=p(A)p(x_{1b}|x_2^*,x_3^*)
$$

如果我们构造转移概率 kernel $q_1$，使得$\begin{cases}q_1(A,B)=p(x_{1b}|x_2^*,x_3^*)\\q_1(B,A)=p(x_{1a}|x_2^*,x_3^*)\end{cases}$，则在$A,B$两点$q_1$与目标分布$p$满足细致平稳条件。
这样的$q_1$很容易定义出来。若$I=\left[\begin{matrix}x_{1i}\\x_{2i}\\x_{3i}\end{matrix}\right]$和$J=\left[\begin{matrix}x_{1j}\\x_{2j}\\x_{3j}\end{matrix}\right]$ 是状态空间任意两点，定义$q_1$为：
$$
q_1(I,J)=\begin{cases}
p(x_{1j}|x_{2j}, x_{3j})&\text{for  }x_{2i}=x_{2j} \text{ and }x_{3i}=x_{3j}\\
0&\text{for  }x_{2i}\not=x_{2j} \text{ or }x_{3i}\not=x_{3j}\\
\end{cases}
$$
> $x_{2i}=x_{2j}$且$x_{3i}=x_{3j}$时，直接在 $q_1(I,J)$ 和 $p(x_{1j}|x_{2j}, x_{3j})$ 之间划等号其实是不准确的 (但这并不影响之后的结论)，事实上我们应该写成： $q_1(I,J)\propto p(x_{1j}|x_{2j}, x_{3j})$；因为当$I$固定时$q_1(I,J)$是关于$J$的分布，这个分布应该是$d_x$维的(本例中是3维)，而$p(x_{1j}|x_{2j}, x_{3j})$只是个一维的分布：$q_1(I,J)$给出的概率密度是三维空间中的密度，$p(x_{1j}|x_{2j}, x_{3j})$则代表线密度。所以，$q_1(I,J)$是嵌入到$d_x(3)$维空间中的一个一维分布, 在数值上， 当$x_{2i}=x_{2j}$且$x_{3i}=x_{3j}$时，$q_1(I,J)=\infty$；但在比例上$q_1(I,J)\propto p(x_{1j}|x_{2j}, x_{3j})$。

这样$q_1$就在整个状态空间内满足细致平稳条件了。
那我们是否可以直接以$q_1$为kernel进行MCMC采样得到目标分布$p(x)$的样本呢？
不行! 因为我们这个$q_1$，**并不是ergodic的**！比如，从状态$A$出发，以$q_1$为kernel进行转移，如果$x_{2b}\not=x_{2a}$或$x_{3b}\not=x_{3a}$，那无论转移多少次，$A$转移到$B$的概率始终是0，$A$和$B$是不连通的！
怎么解决？
我们可以按照$q_1$的形式，继续构造kernel $q_2$和$q_3$，分别定义如下：
$$
q_2(I,J)=\begin{cases}
p(x_{2j}|x_{3j}, x_{1j})&\text{for  }x_{3i}=x_{3j} \text{ and }x_{1i}=x_{1j}\\
0&\text{for  }x_{3i}\not=x_{3j} \text{ or }x_{1i}\not=x_{1j}\\
\end{cases}\\
q_3(I,J)=\begin{cases}
p(x_{3j}|x_{1j}, x_{2j})&\text{for  }x_{1i}=x_{1j} \text{ and }x_{2i}=x_{2j}\\
0&\text{for  }x_{1i}\not=x_{1j} \text{ or }x_{2i}\not=x_{2j}\\
\end{cases}
$$
显然，$q_1,q_2,q_3$都不是ergodic的；
但是，它们的组合$q$是ergodic的，kernel $q$定义如下:
$$
q(I,J)=\frac{1}{d_x}\sum_{h=1}^{d_x}q_h(I,J)
$$
其中$d_x$是状态空间的维数，本例中$d_x=3$。容易证明$q$也是满足细致平稳条件的。
我们利用这个$q$来构造Markov Chain就可以对目标分布$p(x)$进行MCMC采样了。
$q(I,x)$是随机向量$x$的一个**有限混合分布**，从$q(I,x)$中采样$x$时，我们首先按照平均的几率选择一个维$h$，然后对$q_h(I,x)$采样一个点，这样采到的点符合混合分布$q(I,x)$。可以用预备知识1中提到的采样准则来检验一下这种采样方式的合理性。

#### Gibbs 采样法的完整流程

采样开始前，选定 kernel $q$：$q(I,J)=\frac{1}{d_x}\sum_{h=1}^{d_x}q_h(I,J)$。其中$d_x$是状态空间的维数，$q_h(I,J)$ 的定义参考上一节。Gibbs采样法步骤：
1.  设时刻$k=0$，随意选定初始状态$X_0$；
2.  随机选择一个维 (保证每个维被选中的几率相等，或至少每个维都有被选中的可能)，或按照顺序从集合$\{1,2,3,...d_x\}$中选择一个维，设选择的维是 $h$；
3.  从关于$x$的分布 $q_h(X_{k},x)$中抽样，得到$X$ ： $X\sim q_h(X_{k},x)$
4.  状态转移， $X_{k+1}=X$;
5.  $k=k+1$;
6.  如果$k$超过指定样本数量，采样完成，退出；否则，返回步骤2继续；


### MCMC move

MCMC move 是粒子滤波优化中的一个步骤。它的主要思想是：
- 如果我们已经按照某种抽样方法从目标分布$p(x)$中得到了一个样本集$S=\{X_1,X_2,X_3...,X_n\}$，$q(x_i,x_j)$是一个能与$p(x)$满足细致平稳条件的kernel。接下来我们对样本集$S$中的每个样本，按照kernel $q$进行一步Markov转移，得到一组新的样本$S'=\{X_1',X_2',X_3'...X_n'\}$，则样本集$S'$也符合目标分布$p(x)$。
> 设分布$p(x)$按照kernel $q$发生一次概率转移后，生成的新分布为$p'(x)$，则：
$$ p'(x)=\int_{\Omega}p(x_i)q(x_i,x)dx_i \\
 \text{(apply detailed balance condition根据细致平稳条件)}\\
 \Downarrow \\
p'(x)=\int_{\Omega}p(x)q(x,x_i)dx_i=p(x)\times \int_{\Omega}q(x,x_i)dx_i  \\
\int_{\Omega} q(x,x_i)dx_i=1  \text{  因为} q(x,x_i)\text{是}x_i\text{的一个分布函数，全概率是}1\\
\Downarrow\\
p'(x)=p(x)\times 1=p(x) $$

因此转移后的样本集依然服从分布$p(x)$。

MCMC move 过程本质上等价于从有限混合分布$P(x)$
$$
P(x)=\sum_{i=1}^{n}\frac{1}{n}q(X_i,x)
$$
中抽样$n$个点。即从各子分布$q(X_i,x)$分别抽样一个点$X_i'$ : $X_i'\sim q(X_i,x)$

有别于MCMC采样的一点是，**进行MCMC move并不要求kernel $q$是ergodic的**！只要满足细致平稳条件，就足够。
这并不难理解，MCMC采样是从0开始，生成整个样本集，所以使用的kernel必须是ergodic的，否则不能遍历整个状态空间，就不能充足采样；
而MCMC move 在工作时，已经有了一组现成的、充足的样本集，这时只要kernel满足细致平稳条件就可以生成另一组符合目标分布的样本。


## 粒子轨迹

在讲解粒子滤波的文献中，都是通过考虑在整个$1$到$t$时刻之间**粒子轨迹$\boldsymbol{x}_{1:t}$**的分布$p(\boldsymbol{x}_{1:t}|\boldsymbol{y}_{1:t})$，计算出权重$w_t$的形式，再由模型的**马尔科夫**假设，得到$t$时刻与$(t-1)$时刻权重的关系，从而将$w_t$拆成递推形式的。
这种直接考虑粒子在所有时刻轨迹的方法，对于初次接触粒子滤波的人，可能带来理解上的生涩；
本文上面的解释中，则是直接考虑$t$时刻与$(t-1)$时刻的关系，没有引入轨迹$\boldsymbol{x}_{1:t}$，比较适合学习过卡尔曼滤波的人来理解。
当然，无论哪种解释，最后得出的结论和公式是相同的。
下面会讲，如何用粒子轨迹来解释粒子滤波的过程。而且，如果想了解 MCMC move等优化步骤，也是应该从粒子轨迹的角度来理解粒子滤波。
> 直接考虑整个轨迹分布$p(\boldsymbol{x}_{1:t}|\boldsymbol{y}_{1:t})$的一个奇妙之处是：滤波(filtering)和平滑(smoothing)被一起实现了：我们知道，如果获得了$(1:t)$时刻的所有观测值$\boldsymbol{y}_{1:t}$，对于时刻$j$($j<t$)，滤波(filtering)求的是$p(\boldsymbol{x}_j|\boldsymbol{y}_{1:j})$；而平滑(smoothing)求的是$p(\boldsymbol{x}_j|\boldsymbol{y}_{1:t})$，即在估计$j$时刻的状态分布时，平滑(smoothing)还会使用"未来"数据；而如果求出$p(\boldsymbol{x}_{1:t}|\boldsymbol{y}_{1:t})$，相当于$1:t$时刻全部被平滑了。
直接考虑粒子各时刻轨迹的这种思想，体现在粒子滤波中就是：
- 每一时刻，我们为某个粒子分配的权重，其实就是该粒子所在轨迹的权重；
- 重采样(后面会讲)过程中，每复制或丢弃一个粒子，其实就是复制或丢弃了该粒子所在的轨迹；

> 这相当于"打包"更新了所有历史时刻的分布！时时刻刻在做平滑！
但在实现时，我们通常只保留上一时刻的粒子，而不会保存整个轨迹（那将非常占用资源）; 
而且，即便是保存了这些轨迹，这样的smoothing效果也不会很好，因为重采样过程引起的样本贫化现象，对越早的时刻，影响越越严重：比如，如果$(t-1)$时刻样本权重不均衡，导致了重采样后样本多样性缩小到只剩一个样本；进入$t$时刻后，通过重要性采样重新获得$N$个轨迹，$t$时刻的粒子多样性会稍有所增长，但$(0:t-1)$时刻的轨迹依然只有一条！随着时间增长，更早时刻的分布会迅速丢失。当然，通过MCMC move可以减轻样本贫化，但在粒子滤波的实现中，我们只对$t$时刻的粒子做转移，减少$t$时刻的粒子重叠现象，而之前时刻的粒子依然会重叠。可以读完后面关于样本贫化现象的介绍再来理解这段话。


### 从粒子轨迹角度理解粒子滤波

粒子滤波前，我们都会对系统的初始状态$\boldsymbol{x}_0$ 有一个先验估计，设这个先验分布为$p(\boldsymbol{x}_0)$。
$\boldsymbol{x}_0$对应时刻$0$，是我们虚拟的一个时刻。
我们不妨把时刻$0$的状态也算到状态轨迹中，这样$t$时刻的状态轨迹就用$\boldsymbol{x}_{0:t}$来表示。
$0$时刻没有观测指，因此观测值$\boldsymbol{y}_{1:t}$的下标还是从$1$开始。
$t$时刻的后验轨迹分布为: $p(\boldsymbol{x}_{0:t}|\boldsymbol{y}_{1:t})$。
> 由于系统的状态转移函数、观测函数、以及噪声模型都是已知的，因此当我们选定先验分布$p(\boldsymbol{x}_0)$时，所有时刻的状态、观测值的分布就被确定了。
即理论上，选定$p(\boldsymbol{x}_0)$时，对任意时刻$t$，我们已经可以确定$(\boldsymbol{x}_{0:t},\boldsymbol{y}_{1:t})$ 的联合分布$p(\boldsymbol{x}_{0:t},\boldsymbol{y}_{1:t})$了，所有的边缘分布$p(\boldsymbol{y}_{1:t}),p(\boldsymbol{x}_{0:t})$，和条件分布$p(\boldsymbol{x}_{0:t}|\boldsymbol{y}_{1:t})$自然也被确定。
我们滤波或平滑的过程，就是选定一组观测值$\boldsymbol{y}_{1:t}$后，从联合分布$p(\boldsymbol{x}_{0:t},\boldsymbol{y}_{1:t})$中求出条件概率分布$p(\boldsymbol{x}_{0:t}|\boldsymbol{y}_{1:t})$的过程。

$$
p(\boldsymbol{x}_{0:t}|\boldsymbol{y}_{1:t}) = p(\boldsymbol{x}_{0:t}|\boldsymbol{y}_{t},\boldsymbol{y}_{1:t-1}) = \frac{p(\boldsymbol{x}_{0:t}|\boldsymbol{y}_{1:t-1})p(\boldsymbol{y}_{t}|\boldsymbol{x}_{0:t},\boldsymbol{y}_{1:t-1})}{p(\boldsymbol{y}_{t}|\boldsymbol{y}_{1:t-1})}
$$
当给定观测值$\boldsymbol{y}_{1:t}$时，$p(\boldsymbol{y}_{t}|\boldsymbol{y}_{1:t-1})$是常数，设$\alpha=\frac{1}{p(\boldsymbol{y}_{t}|\boldsymbol{y}_{1:t-1})}$。则
$$
p(\boldsymbol{x}_{0:t}|\boldsymbol{y}_{1:t}) = \alpha p(\boldsymbol{x}_{0:t}|\boldsymbol{y}_{1:t-1})p(\boldsymbol{y}_{t}|\boldsymbol{x}_{0:t},\boldsymbol{y}_{1:t-1}) = \\
\left[\int \alpha p(\boldsymbol{x}^*_{0:t-1}|\boldsymbol{y}_{1:t-1})p(\boldsymbol{x}_{0:t}|\boldsymbol{x}^*_{0:t-1},\boldsymbol{y}_{1:t-1})d\boldsymbol{x}^*_{0:t-1} \right] p(\boldsymbol{y}_{t}|\boldsymbol{x}_{0:t},\boldsymbol{y}_{1:t-1})
$$

系统的状态转移是马尔可夫的，$\boldsymbol{x}_{t}$ 只依赖于 $\boldsymbol{x}_{t-1}$，所以
$$
p(\boldsymbol{x}_{0:t}|\boldsymbol{x}^*_{0:t-1},\boldsymbol{y}_{1:t-1})=p(\boldsymbol{x}_{0:t}|\boldsymbol{x}^*_{0:t-1})=\begin{cases}
0&\text{for  }\boldsymbol{x}_{0:t-1}\not=\boldsymbol{x}^*_{0:t-1}\\
p(\boldsymbol{x}_{t}|\boldsymbol{x}^*_{t-1})&\text{for  }\boldsymbol{x}_{0:t-1}=\boldsymbol{x}^*_{0:t-1}\\
\end{cases}
$$
> $\boldsymbol{x}_{0:t-1}=\boldsymbol{x}^*_{0:t-1}$时，直接在$p(\boldsymbol{x}_{0:t}|\boldsymbol{x}^*_{0:t-1})$和$p(\boldsymbol{x}_{t}|\boldsymbol{x}^*_{t-1})$ 之间划等号其实是不准确的，事实上我们应该写成：$p(\boldsymbol{x}_{0:t}|\boldsymbol{x}^*_{0:t-1})\propto p(\boldsymbol{x}_{t}|\boldsymbol{x}^*_{t-1})$；因为前者是关于$\boldsymbol{x}_{0:t}$的分布，这个分布是$[(t+1)d_x]$维的；而后者是关于$\boldsymbol{x}_{t}$的、$d_x$维的分布。所以，$p(\boldsymbol{x}_{0:t}|\boldsymbol{x}^*_{0:t-1})$ 其实是嵌入到$Nd_x$维空间中的一个低维($d_x$维)分布，在数值上，当$\boldsymbol{x}_{0:t-1}=\boldsymbol{x}^*_{0:t-1}$时，$p(\boldsymbol{x}_{0:t}|\boldsymbol{x}^*_{0:t-1})=\infty$，但在比例上$p(\boldsymbol{x}_{0:t}|\boldsymbol{x}^*_{0:t-1})\propto p(\boldsymbol{x}_{t}|\boldsymbol{x}^*_{t-1})$。
但我们直接写成等号并不影响推导结果的正确性。之后的小节中还会有类似的情况，不再小框说明。

$t$时刻的观测值$\boldsymbol{y}_{t}$只依赖于$\boldsymbol{x}_{t}$，所以$p(\boldsymbol{y}_{t}|\boldsymbol{x}_{0:t},\boldsymbol{y}_{1:t-1})=p(\boldsymbol{y}_{t}|\boldsymbol{x}_{t})$；
于是
$$
p(\boldsymbol{x}_{0:t}|\boldsymbol{y}_{1:t}) = \left[\int \alpha p(\boldsymbol{x}^*_{0:t-1}|\boldsymbol{y}_{1:t-1})p(\boldsymbol{x}_{0:t}|\boldsymbol{x}^*_{0:t-1})d\boldsymbol{x}^*_{0:t-1} \right] p(\boldsymbol{y}_{t}|\boldsymbol{x}_{t})=\\
\int \alpha p(\boldsymbol{x}^*_{0:t-1}|\boldsymbol{y}_{1:t-1})p(\boldsymbol{x}_{0:t}|\boldsymbol{x}^*_{0:t-1})p(\boldsymbol{y}_{t}|\boldsymbol{x}_{t})d\boldsymbol{x}^*_{0:t-1}
$$

$p(\boldsymbol{x}_{0:t-1}|\boldsymbol{y}_{1:t-1})$是$(t-1)$时刻的后验轨迹分布，上面的积分是关于$\boldsymbol{x}_{0:t-1}$的全概率积分，可以用蒙特卡洛法近似。
设$\{\boldsymbol{x}_{0:t-1}^{(i)},\overline{w}_{t-1}^{(i)}|i=1,2,3...N\}$是$p(\boldsymbol{x}_{0:t-1}|\boldsymbol{y}_{1:t-1})$的$N$个轨迹样本，$\overline{w}_{t-1}^{(i)}$ 是归一化的权重，则：
$$
p(\boldsymbol{x}_{0:t}|\boldsymbol{y}_{1:t})\approx \sum_{i=0}^{N}\overline{w}_{t-1}^{(i)}\alpha p(\boldsymbol{x}_{0:t}|\boldsymbol{x}_{0:t-1}^{(i)})p(\boldsymbol{y}_{t}|\boldsymbol{x}_{t})
$$
为了方便表示我们令$\widetilde{p}_t(\boldsymbol{x}_{0:t})=\sum_{i=0}^{N}\overline{w}_{t-1}^{(i)}\alpha p(\boldsymbol{x}_{0:t}|\boldsymbol{x}_{0:t-1}^{(i)})p(\boldsymbol{y}_{t}|\boldsymbol{x}_{t})$
这样就得到了$t$时刻的近似后验分布$\widetilde{p}_t(\boldsymbol{x}_{0:t})$。但这个分布太复杂，我们还是希望用服从该分布的一些样本来代表它。

#### 重要性采样
$\widetilde{p}_t(\boldsymbol{x}_{0:t})$是个有限混合分布，它的第$i$个子分布是 
$$
\alpha p(\boldsymbol{x}_{0:t}|\boldsymbol{x}_{0:t-1}^{(i)})p(\boldsymbol{y}_{t}|\boldsymbol{x}_{t})=\begin{cases}
0&\text{for  }\boldsymbol{x}_{0:t-1}\not=\boldsymbol{x}^{(i)}_{0:t-1}\\
\alpha p(\boldsymbol{x}_{t}|\boldsymbol{x}^{(i)}_{t-1})p(\boldsymbol{y}_{t}|\boldsymbol{x}_{t})&\text{for  }\boldsymbol{x}_{0:t-1}=\boldsymbol{x}^{(i)}_{0:t-1}\\
\end{cases}
$$
> 其实 $[\alpha p(\boldsymbol{x}_{t}|\boldsymbol{x}^{(i)}_{t-1})p(\boldsymbol{y}_{t}|\boldsymbol{x}_{t})]$ 并算不上是$\boldsymbol{x}_{t}$的一个分布函数，因为 $\int \alpha p(\boldsymbol{x}_{t}|\boldsymbol{x}^{(i)}_{t-1})p(\boldsymbol{y}_{t}|\boldsymbol{x}_{t}) d\boldsymbol{x}_{t} \not= 1$。但我们可以简单改造一下使它变成分布函数。比如设$c^{(i)}=\int \alpha p(\boldsymbol{x}_{t}|\boldsymbol{x}^{(i)}_{t-1})p(\boldsymbol{y}_{t}|\boldsymbol{x}_{t}) d\boldsymbol{x}_{t}$，则
$\frac{\alpha p(\boldsymbol{x}_{t}|\boldsymbol{x}^{(i)}_{t-1})p(\boldsymbol{y}_{t}|\boldsymbol{x}_{t})}{c^{(i)}}$ 是$\boldsymbol{x}_{t}$的一个分布函数，相应的，该子分布的权重变为$\overline{w}_{t-1}^{(i)}c^{(i)}$；


我们为该子分布设计的 proposal 分布也应有这样的形式：
$$
q_t^{(i)}(\boldsymbol{x}_{0:t})=\begin{cases}
0&\text{for  }\boldsymbol{x}_{0:t-1}\not=\boldsymbol{x}^{(i)}_{0:t-1}\\
q_t^{(i)}(\boldsymbol{x}_{t})&\text{for  }\boldsymbol{x}_{0:t-1}=\boldsymbol{x}^{(i)}_{0:t-1}\\
\end{cases}
$$
这样设计proposal 分布的理由是：假如我们从 proposal 分布$q_t^{(i)}(\boldsymbol{x}_{0:t})$中采样到一个轨迹 $\widehat{\boldsymbol{x}}^*_{0:t}$，且$\widehat{\boldsymbol{x}}^*_{0:t-1}\not=\boldsymbol{x}^{(i)}_{0:t-1}$, 那这个轨迹样本的重要性权重就是$[\overline{w}_{t-1}^{(i)}c^{(i)}\frac{\alpha p(\widehat{\boldsymbol{x}}^*_{0:t}|\boldsymbol{x}_{0:t-1}^{(i)})p(\boldsymbol{y}_{t}|\widehat{\boldsymbol{x}}^*_{t})}{c^{(i)}q_t^{(i)}(\widehat{\boldsymbol{x}}^*_{0:t})}]=[\overline{w}_{t-1}^{(i)}c^{(i)}\frac{0\times \alpha p(\boldsymbol{y}_{t}|\widehat{\boldsymbol{x}}^*_{t})}{c^{(i)}q_t^{(i)}(\widehat{\boldsymbol{x}}^*_{0:t})}]=0$，这样的样本是无效的。 因此我们设计的$q_t^{(i)}(\boldsymbol{x}_{0:t})$应该防止这样的样本被采到。

这意味着当我们需要从$q_t^{(i)}(\boldsymbol{x}_{0:t})$中采样一个轨迹$\widehat{\boldsymbol{x}}^*_{0:t}$时，只需要从分布$q_t^{(i)}(\boldsymbol{x}_{t})$中为$t$时刻采样一个粒子$\widehat{\boldsymbol{x}}^*_{t}$，然后令轨迹$\widehat{\boldsymbol{x}}^*_{0:t}=[\boldsymbol{x}^{(i)}_{0:t-1}, \widehat{\boldsymbol{x}}^*_{t}]$即可。
设$\widehat{\boldsymbol{x}}^{(1)}_{0:t},\widehat{\boldsymbol{x}}^{(2)}_{0:t},\widehat{\boldsymbol{x}}^{(3)}_{0:t}...\widehat{\boldsymbol{x}}^{(N)}_{0:t}$ 分别是从$q_t^{(1)}(\boldsymbol{x}_{0:t}),q_t^{(2)}(\boldsymbol{x}_{0:t}),q_t^{(3)}(\boldsymbol{x}_{0:t})...q_t^{(N)}(\boldsymbol{x}_{0:t})$中采样的轨迹，则根据预备知识中的结论1和结论4，有限混合分布$\widetilde{p}_t(\boldsymbol{x}_{0:t})$  可被近似为：
$$\widetilde{p}_t(\boldsymbol{x}_{0:t})\sim \widehat{p}_t(\boldsymbol{x}_{0:t}) = \sum_{i=0}^{N}(w_{t}^{(i)}/W)\delta(\boldsymbol{x}_{t}-\widehat{\boldsymbol{x}}^{(i)}_{0:t}) = \sum_{i=0}^{N}\widetilde{w}_{t}^{(i)}\delta(\boldsymbol{x}_{t}-\widehat{\boldsymbol{x}}^{(i)}_{0:t})$$

其中，$w_{t}^{(i)}=\overline{w}_{t-1}^{(i)}c_t^{(i)}\frac{\alpha p(\widehat{\boldsymbol{x}}_{0:t}^{(i)}|\boldsymbol{x}_{0:t-1}^{(i)})p(\boldsymbol{y}_t|\widehat{\boldsymbol{x}}_t^{(i)})}{c_t^{(i)}q_t^{(i)}(\widehat{\boldsymbol{x}}_{0:t}^{(i)})}$是$t$时刻第$i$个轨迹样本的权重（**结论1**）；由于我们采到的轨迹样本都满足$\widehat{\boldsymbol{x}}_{0:t-1}^{(i)} = \boldsymbol{x}_{0:t-1}^{(i)}$，因此$\begin{cases}p(\widehat{\boldsymbol{x}}_{0:t}^{(i)}|\boldsymbol{x}_{0:t-1}^{(i)})=p(\widehat{\boldsymbol{x}}_{t}^{(i)}|\boldsymbol{x}_{t-1}^{(i)})\\q_t^{(i)}(\widehat{\boldsymbol{x}}_{0:t}^{(i)})=q_t^{(i)}(\widehat{\boldsymbol{x}}_{t}^{(i)})\end{cases}$；常数$\alpha$不会影响归一化后的权重，所以我们可以忽略它；于是我们可以按 $$w_{t}^{(i)}=\overline{w}_{t-1}^{(i)}\frac{p(\widehat{\boldsymbol{x}}_t^{(i)}|\boldsymbol{x}_{t-1}^{(i)})p(\boldsymbol{y}_t|\widehat{\boldsymbol{x}}_t^{(i)})}{q_t^{(i)}(\widehat{\boldsymbol{x}}_t^{(i)})}$$
来计算权重，可以看出这与之前不考虑轨迹时推出来的权重是一样的；
$W_t=\sum_{i=1}^{N}{w_{t}^{(i)}}$是$t$时刻粒子总权重，
$\widetilde{w}_{t}^{(i)}=\frac{w_{t}^{(i)}}{W_t}$是$t$时刻第$i$个粒子的归一化权重。

这样，我们就采集到了近似服从$t$时刻后验轨迹分布$p(\boldsymbol{x}_{0:t}|\boldsymbol{y}_{1:t})$的一组带权重的样本集$\{\widehat{\boldsymbol{x}}_{t}^{(i)}, \widetilde{w}_{t}^{(i)} | i=1,2,3...N\}$，注意每个样本是一条轨迹。只不过，这些轨迹样本与$(t-1)$时刻的轨迹样本$\{\boldsymbol{x}_{0:t-1}^{(i)}\}$，在时刻$(0:t-1)$之间是重叠的。
**重要性采样过程会保持$0:(t-1)$时刻的粒子轨迹不变，只为$t$时刻添加新粒子**。

#### 重采样
接下来，我们进行重采样来得到权重均衡的一组新样本，重采样本质上是从离散分布 $\widehat{p}_t(\boldsymbol{x}_{0:t})=\sum_{i=0}^{N}\widetilde{w}_{t}^{(i)}\delta(\boldsymbol{x}_{0:t}-\widehat{\boldsymbol{x}}^{(i)}_{0:t})$ 中重新采集$N$个等权重的轨迹样本，具体采样方法与前文类似，不再重复。再强调一次，现在采样得到的每个样本，不再是一个粒子，而都是一个"轨迹"：每个轨迹由$(0:t)$时刻的共(t+1)个粒子组成。
重采样过程倾向于丢弃权重小的轨迹，复制权重大的轨迹。
将我们重采样得到的轨迹样本集记为$\{\widetilde{\boldsymbol{x}}_{0:t}^{(i)}, \overline{w}_t^{(i)}=(1/N) | i=1,2,3...N\}$，我们就可以用一个新的分布$\overline{p}(\boldsymbol{x}_{0:t})$来近似$t$时刻的后验轨迹分布：
$$
p(\boldsymbol{x}_{0:t}|\boldsymbol{y}_{1:t})\sim \overline{p}(\boldsymbol{x}_{0:t})=\sum_{i=1}^{N}{\overline{w}_{t}^{(i)}\delta(\boldsymbol{x}_{0:t}-\widetilde{\boldsymbol{x}}_{0:t}^{(i)})}=\sum_{i=1}^{N}{(1/N)\delta(\boldsymbol{x}_{0:t}-\widetilde{\boldsymbol{x}}_{0:t}^{(i)})}
$$


#### 考虑粒子轨迹的通用粒子滤波流程

现在我们可以重写通用粒子滤波的流程如下：

1. 时刻$t=0$，采样初始粒子： 
 - $\text{for }i=0,1,2....,N$，采样$\boldsymbol{x}_0^{(i)}\sim p(\boldsymbol{x}_0)$，设置权重$\overline{w}_0^{(i)}=1/N$

2. $t=t+1$;
3. 重要性采样：
 - 从 proposal 分布中采样并计算重要性权重：
$\text{for }i=0,1,2....,N$，采样 $\widehat{\boldsymbol{x}}_{t}^{(i)}\sim q_t^{(i)}(\boldsymbol{x}_{t})$，设置轨迹$\widehat{\boldsymbol{x}}_{0:t}^{(i)}=[\boldsymbol{x}_{0:t-1}^{(i)}, \widehat{\boldsymbol{x}}_{t}^{(i)}]$，计算轨迹权重$w_t^{(i)}=\overline{w}_{t-1}^{(i)}\frac{p(\widehat{\boldsymbol{x}}_{t}^{(i)}|\boldsymbol{x}_{t-1}^{(i)})p(\boldsymbol{y}_t|\widehat{\boldsymbol{x}}_{t}^{(i)})}{q_t^{(i)}(\boldsymbol{x}_{t})}$
 - 归一化权重：
$\text{for }i=0,1,2....,N$， 计算 $\widetilde{w}_t^{(i)}=w_t^{(i)}/(\sum_i^N{w_t^{(i)}})$.

4. 重采样：
从离散分布 $\widehat{p}(\boldsymbol{x}_{0:t}) = \sum_{i=1}^{N}{\widetilde{w}_{t}^{(i)}\delta(\boldsymbol{x}_{0:t}-\widehat{\boldsymbol{x}}_{0:t}^{(i)})}$ 中采样$N$个新轨迹，每个新轨迹权重为$(1/N)$，得到$\{\widetilde{\boldsymbol{x}}_{0:t}^{(i)}, \overline{w}_{t}^{(i)}=(1/N)|i=1,2,3...N\}$

5. $\text{for }i=0,1,2....,N$，$\boldsymbol{x}_{0:t}^{(i)}=\widetilde{\boldsymbol{x}}_{0:t}^{(i)}$
6. 输出结果：
$$E[g(\boldsymbol{x}_{0:t})]=(1/N)\sum_{i=1}^{N}g(\boldsymbol{x}_{0:t}^{(i)})$$
返回步骤 2 处理下一时刻


虽然上面的步骤中，我们用的都是轨迹，但实际我们在实现时，通常仅记录上一时刻的粒子就够了。
所以这个流程与之前未考虑轨迹的粒子滤波流程基本是一样的。


## 重采样引起的样本贫化问题

前面提到，重采样过程本质上就是从离散分布 
$$
\widehat{p}_t(\boldsymbol{x}_{0:t})=\sum_{i=0}^{N}\widetilde{w}_{t}^{(i)}\delta(\boldsymbol{x}_{0:t}-\widehat{\boldsymbol{x}}^{(i)}_{0:t})
$$
中重新采样$N$个等权重的轨迹 :  经过重采样后，**所有轨迹的权重恢复到$\overline{w}_t^{(i)}=1/N$，有效样本数也恢复到$N_{eff}=N$**。
但是，经过这样的重采样后，样本集里出现了很多**重复轨迹**。最极端的情况，当重采样之前，某一个轨迹权重接近1而其他所有轨迹权重都很小时，重采样后很可能得到$N$个完全一样的轨迹，这导致样本贫化问题，即**粒子的多样性**丧失 (或轨迹的多样性)，这限制了用粒子表达分布的能力：所有粒子集中在概率密度高的区域，而概率密度稍低些的区域的分布信息完全被丢弃。This degeneracy will limit  the ability of the algorithm to search for lower minima in other regions of the error surface。

为了对付样本贫化，有两种思路可寻。

### 正则化（Regularized）粒子滤波

在重采样阶段，不再是对离散分布 $\widehat{p}_t(\boldsymbol{x}_{0:t})=\sum_{i=0}^{N}\widetilde{w}_{t}^{(i)}\delta(\boldsymbol{x}_{t}-\widehat{\boldsymbol{x}}^{(i)}_{0:t})$ 采样，而是而构造一个**连续**的**有限混合分布**$\widehat{p}_{(K)}(\boldsymbol{x}_{0:t})$，如
$$\widehat{p}_{(K)}(\boldsymbol{x}_{0:t})=\sum_{i=1}^{N}{\widetilde{w}_{0:t}^{(i)}K^{(i)}(\boldsymbol{x}_{0:t}-\widehat{\boldsymbol{x}}_{0:t}^{(i)})}
$$
其中 $K^{(i)}(\boldsymbol{x}_{0:t}-\widehat{\boldsymbol{x}}_{0:t}^{(i)})$ 是一个以$\widehat{\boldsymbol{x}}_{0:t}^{(i)}$为中心的 Kernel 函数。
然后从分布$\widehat{p}_{(K)}(\boldsymbol{x}_{0:t})$中进行重采样。由于$\widehat{p}_{(K)}(\boldsymbol{x}_{0:t})$是连续分布，对它重采样几乎不会再出现重复样本。
我们还是应保持 $(0:t-1)$时刻的粒子轨迹不变，只更新$t$时刻粒子： 毕竟粒子滤波的主要目的是filtering而不是smoothing，而且这样实现起来比较简单，不用存储轨迹。
所以我们选择的 Kernel 函数应该有这样的形式：
$$
K^{(i)}(\boldsymbol{x}_{0:t}-\widehat{\boldsymbol{x}}_{0:t}^{(i)})=\begin{cases}
0&\text{for  }\boldsymbol{x}_{0:t-1}\not= \widehat{\boldsymbol{x}}_{0:t-1}^{(i)}\\
K^{(i)}(\boldsymbol{x}_{t}-\widehat{\boldsymbol{x}}_{t}^{(i)})&\text{for  }\boldsymbol{x}_{0:t-1}= \widehat{\boldsymbol{x}}_{0:t-1}^{(i)}
\end{cases}
$$

从$\widehat{p}_{(K)}(\boldsymbol{x}_{0:t})$采样时，先从$[0,1]$均匀分布中采集一个随机数，根据抽取的随机数选定$p_{(K)}(\boldsymbol{x}_{0:t})$的一个子分布，比如选定的是$K^{(i)}(\boldsymbol{x}_{0:t}-\widehat{\boldsymbol{x}}_{0:t}^{(i)})$（该子分布被选中的概率是$\widetilde{w}_{t}^{(i)}$），再从$K^{(i)}(\boldsymbol{x}_{0:t}-\widehat{\boldsymbol{x}}_{0:t}^{(i)})$中采集一个点。
前述的过程其实等价于先用常规重采样法采样得到等权重样本集$\{\widetilde{\boldsymbol{x}}_{0:t}^{(i)}|i=1:N\}$， 再从每个$K^{(i)}(\boldsymbol{x}_{0:t}-\widetilde{\boldsymbol{x}}_{0:t}^{(i)})$中采样一个轨迹${\boldsymbol{x}_{0:t}^{(i)}}$，来替代对应的$\widetilde{\boldsymbol{x}}_{0:t}^{(i)}$。


因此，实现正则化粒子滤波时，只需将前面讲到的常规粒子滤波的第5步改为：

1. 时刻$t=0$，采样初始粒子： 
 - $\text{for }i=0,1,2....,N$，采样$\boldsymbol{x}_0^{(i)}\sim p(\boldsymbol{x}_0)$，设置权重$\overline{w}_0^{(i)}=1/N$

2. $t=t+1$;
3. 重要性采样：
 - 从 proposal 分布中采样并计算重要性权重：
$\text{for }i=0,1,2....,N$，采样 $\widehat{\boldsymbol{x}}_{t}^{(i)}\sim q_t^{(i)}(\boldsymbol{x}_{t})$，设置轨迹$\widehat{\boldsymbol{x}}_{0:t}^{(i)}=[\boldsymbol{x}_{0:t-1}^{(i)}, \widehat{\boldsymbol{x}}_{t}^{(i)}]$，计算轨迹权重$w_t^{(i)}=\overline{w}_{t-1}^{(i)}\frac{p(\widehat{\boldsymbol{x}}_{t}^{(i)}|\boldsymbol{x}_{t-1}^{(i)})p(\boldsymbol{y}_t|\widehat{\boldsymbol{x}}_{t}^{(i)})}{q_t^{(i)}(\boldsymbol{x}_{t})}$
 - 归一化权重：
$\text{for }i=0,1,2....,N$， 计算 $\widetilde{w}_t^{(i)}=w_t^{(i)}/(\sum_i^N{w_t^{(i)}})$.

4. 重采样：
从离散分布 $\widehat{p}(\boldsymbol{x}_{0:t}) = \sum_{i=1}^{N}{\widetilde{w}_{t}^{(i)}\delta(\boldsymbol{x}_{0:t}-\widehat{\boldsymbol{x}}_{0:t}^{(i)})}$ 中采样$N$个新轨迹，每个新轨迹权重为$(1/N)$，得到$\{\widetilde{\boldsymbol{x}}_{0:t}^{(i)}, \overline{w}_{t}^{(i)}=(1/N)|i=1,2,3...N\}$
5. $\text{for }i=0,1,2....,N$，采样 $\boldsymbol{x}_{t}^{(i)}\sim K(\boldsymbol{x}_{t}-\widetilde{\boldsymbol{x}}_{t}^{(i)})$，并设置 $\boldsymbol{x}_{0:t}^{(i)} = [\widetilde{\boldsymbol{x}}_{0:t-1}^{(i)}, \boldsymbol{x}_{t}^{(i)}]$

6. 输出结果，跳回2进入下一时刻；


> 关于常见的 Kernel :
摘自： https://en.wikipedia.org/wiki/Kernel_density_estimation
A range of kernel functions are commonly used: uniform, triangular, biweight, triweight, Epanechnikov, normal, and others. The **Epanechnikov kernel is optimal in a mean square error sense**, though the loss of efficiency is small for the kernels listed previously,[4] and due to its convenient mathematical properties, the normal kernel is often used, which means K(x) = ϕ(x), where ϕ is the standard normal density function.
一些常用的Kernel图像如下：（ 当然Wiki上列举了不少：https://en.wikipedia.org/wiki/Kernel_(statistics) ）
![](https://github.com/NewThinker-Jeffrey/Figures/raw/main/figures/3d60cd0442f50c81496b5c46d10e14a3.png)
![](https://github.com/NewThinker-Jeffrey/Figures/raw/main/figures/f2dce599e39611d02e744398b1862588.png)


 
 
### 粒子滤波中的 MCMC Move

为了维持样本多样性，可在重采样结束后，对轨迹样本集$\{\widetilde{\boldsymbol{x}}_{0:t}^{(i)}, \overline{w}_{0}^{(i)}|i=1,2,3...N\} $中的各样本再进行一次 MCMC 转移，使粒子轨迹**在不改变分布的情况下，移入到更多感兴趣的区域**。

我们的目标分布是$p(\boldsymbol{x}_{0:t}|\boldsymbol{y}_{1:t})$。要使用 MCMC move方法，首先需要设计概率转移 kernel $q(\widetilde{\boldsymbol{x}}_{0:t}, \boldsymbol{x}_{0:t})$和接受率函数$\alpha (\widetilde{\boldsymbol{x}}_{0:t}, \boldsymbol{x}_{0:t})$，使其满足细致平稳条件，即：
$$ p(\widetilde{\boldsymbol{x}}_{0:t}|\boldsymbol{y}_{1:t}) q(\widetilde{\boldsymbol{x}}_{0:t}, \boldsymbol{x}_{0:t})\alpha (\widetilde{\boldsymbol{x}}_{0:t}, \boldsymbol{x}_{0:t}) =  p(\boldsymbol{x}_{0:t}|\boldsymbol{y}_{1:t}) q(\boldsymbol{x}_{0:t}, \widetilde{\boldsymbol{x}}_{0:t})\alpha (\boldsymbol{x}_{0:t}, \widetilde{\boldsymbol{x}}_{0:t}) $$

注意到 
$$
p(\boldsymbol{x}_{0:t}|\boldsymbol{y}_{1:t}) = \frac{p(\boldsymbol{x}_{0:t})p(\boldsymbol{y}_{1:t}|\boldsymbol{x}_{0:t})}{p(\boldsymbol{y}_{1:t})}=\\
\frac{p(\boldsymbol{x}_{t}|\boldsymbol{x}_{0:t-1})p(\boldsymbol{x}_{0:t-1})p(\boldsymbol{y}_{1:t}|\boldsymbol{x}_{0:t})}{p(\boldsymbol{y}_{1:t})}
$$
$\boldsymbol{x}$的状态转移是马尔科夫的，即$\boldsymbol{x}_{t}$只依赖于$\boldsymbol{x}_{t-1}$，因此$p(\boldsymbol{x}_{t}|\boldsymbol{x}_{0:t-1})=p(\boldsymbol{x}_{t}|\boldsymbol{x}_{t-1})$；
$k$时刻的观测值$\boldsymbol{y}_{k}$只依赖于$\boldsymbol{x}_{k}$，因此$p(\boldsymbol{y}_{1:t}|\boldsymbol{x}_{0:t})=\prod_{k=1}^{t}{p(\boldsymbol{y}_{k}|\boldsymbol{x}_{k})}$；
于是
$$
p(\boldsymbol{x}_{0:t}|\boldsymbol{y}_{1:t}) = \frac{p(\boldsymbol{x}_{t}|\boldsymbol{x}_{t-1})p(\boldsymbol{x}_{0:t-1})\prod_{k=1}^{t-1}p(\boldsymbol{y}_{k}|\boldsymbol{x}_{k})}{p(\boldsymbol{y}_{1:t})} = \\
p(\boldsymbol{x}_{t}|\boldsymbol{x}_{t-1})p(\boldsymbol{y}_{t}|\boldsymbol{x}_{t})\frac{p(\boldsymbol{x}_{0:t-1})\prod_{k=1}^{t-1}p(\boldsymbol{y}_{k}|\boldsymbol{x}_{k})}{p(\boldsymbol{y}_{1:t})}
$$

对于任意的 $\widetilde{\boldsymbol{x}}_{0:t}, \boldsymbol{x}_{0:t}$，如果$\widetilde{\boldsymbol{x}}_{0:t-1} = \boldsymbol{x}_{0:t-1}$，则
$$\frac{p(\widetilde{\boldsymbol{x}}_{0:t-1})\prod_{k=1}^{t-1}p(\boldsymbol{y}_{k}|\widetilde{\boldsymbol{x}}_{k})}{p(\boldsymbol{y}_{1:t})} = \frac{p(\boldsymbol{x}_{0:t-1})\prod_{k=1}^{t-1}p(\boldsymbol{y}_{k}|\boldsymbol{x}_{k})}{p(\boldsymbol{y}_{1:t})}$$
因此
$$
\frac{p(\widetilde{\boldsymbol{x}}_{0:t}|\boldsymbol{y}_{1:t})}{p(\boldsymbol{x}_{0:t}|\boldsymbol{y}_{1:t}) }=\frac{p(\widetilde{\boldsymbol{x}}_{t}|\widetilde{\boldsymbol{x}}_{t-1})p(\boldsymbol{y}_{t}|\widetilde{\boldsymbol{x}}_{t})}{p(\boldsymbol{x}_{t}|\boldsymbol{x}_{t-1})p(\boldsymbol{y}_{t}|\boldsymbol{x}_{t})}\\
\Downarrow\\
p(\widetilde{\boldsymbol{x}}_{0:t}|\boldsymbol{y}_{1:t})[p(\boldsymbol{x}_{t}|\boldsymbol{x}_{t-1})p(\boldsymbol{y}_{t}|\boldsymbol{x}_{t})]=p(\boldsymbol{x}_{0:t}|\boldsymbol{y}_{1:t})[p(\widetilde{\boldsymbol{x}}_{t}|\widetilde{\boldsymbol{x}}_{t-1})p(\boldsymbol{y}_{t}|\widetilde{\boldsymbol{x}}_{t})]
$$

当选定 kernel  $q(\widetilde{\boldsymbol{x}}_{0:t}, \boldsymbol{x}_{0:t})$ 后，可定义其接受率函数为 
$$
\alpha (\widetilde{\boldsymbol{x}}_{0:t}, \boldsymbol{x}_{0:t})=\frac{[p(\boldsymbol{x}_{t}|\boldsymbol{x}_{t-1})p(\boldsymbol{y}_{t}|\boldsymbol{x}_{t})]}{q(\widetilde{\boldsymbol{x}}_{0:t}, \boldsymbol{x}_{0:t})} = \frac{[p(\boldsymbol{x}_{t}|\widetilde{\boldsymbol{x}}_{t-1})p(\boldsymbol{y}_{t}|\boldsymbol{x}_{t})]}{q(\widetilde{\boldsymbol{x}}_{0:t}, \boldsymbol{x}_{0:t})} 
$$ 
（上式的第二个等号是因为已假设 $\widetilde{\boldsymbol{x}}_{0:t-1}=\boldsymbol{x}_{0:t-1}\rightarrow \widetilde{\boldsymbol{x}}_{t-1}=\boldsymbol{x}_{t-1}$）
这样就可以满足细致平稳条件了：$p(\widetilde{\boldsymbol{x}}_{0:t}|\boldsymbol{y}_{1:t}) q(\widetilde{\boldsymbol{x}}_{0:t}, \boldsymbol{x}_{0:t})\alpha (\widetilde{\boldsymbol{x}}_{0:t}, \boldsymbol{x}_{0:t}) =  p(\boldsymbol{x}_{0:t}|\boldsymbol{y}_{1:t}) q(\boldsymbol{x}_{0:t}, \widetilde{\boldsymbol{x}}_{0:t})\alpha (\boldsymbol{x}_{0:t}, \widetilde{\boldsymbol{x}}_{0:t}) $。
但以上几个式子都有个前提，就是$\widetilde{\boldsymbol{x}}_{0:t-1} = \boldsymbol{x}_{0:t-1}$，所以kernel  $q(\widetilde{\boldsymbol{x}}_{0:t}, \boldsymbol{x}_{0:t})$ 应有如下的形式：
$$
q(\widetilde{\boldsymbol{x}}_{0:t}, \boldsymbol{x}_{0:t}) = \begin{cases}
0&\text{for  }\widetilde{\boldsymbol{x}}_{0:t-1} \not= \boldsymbol{x}_{0:t-1}\\
q(\widetilde{\boldsymbol{x}}_{t}, \boldsymbol{x}_{t})& \text{for  }\widetilde{\boldsymbol{x}}_{0:t-1} = \boldsymbol{x}_{0:t-1}
\end{cases}
$$
> 这有点像是Gibbs采样中使用的、只在特定的维上进行转移的 kernel ： 我们这里的状态量是轨迹$\boldsymbol{x}_{0:t}$，这是个$[(t+1)d_x]$维的量，而我们的 kernel 只允许$\boldsymbol{x}_{0:t}$在$\boldsymbol{x}_{t}$对应的$d_x$维上转移。
这个kernel也不是ergodic的，但MCMC move并不要求ergodic。

这也说明，我们设计 kernel 时只需要关心$t$时刻的粒子该怎么转移，不用转移$(0:t-1)$时刻之间的整个轨迹。也就是我们只要设计$q(\widetilde{\boldsymbol{x}}_{t}, \boldsymbol{x}_{t})$就可以了。

加上MCMC move后的粒子滤波流程如下：


1. 时刻$t=0$，采样初始粒子： 
 - $\text{for }i=0,1,2....,N$，采样$\boldsymbol{x}_0^{(i)}\sim p(\boldsymbol{x}_0)$，设置权重$\overline{w}_0^{(i)}=1/N$

2. $t=t+1$;
3. 重要性采样：
 - 从 proposal 分布中采样并计算重要性权重：
$\text{for }i=0,1,2....,N$，采样 $\widehat{\boldsymbol{x}}_{t}^{(i)}\sim q_t^{(i)}(\boldsymbol{x}_{t})$，设置轨迹$\widehat{\boldsymbol{x}}_{0:t}^{(i)}=[\boldsymbol{x}_{0:t-1}^{(i)}, \widehat{\boldsymbol{x}}_{t}^{(i)}]$，计算轨迹权重$w_t^{(i)}=\overline{w}_{t-1}^{(i)}\frac{p(\widehat{\boldsymbol{x}}_{t}^{(i)}|\boldsymbol{x}_{t-1}^{(i)})p(\boldsymbol{y}_t|\widehat{\boldsymbol{x}}_{t}^{(i)})}{q_t^{(i)}(\boldsymbol{x}_{t})}$
 - 归一化权重：
$\text{for }i=0,1,2....,N$， 计算 $\widetilde{w}_t^{(i)}=w_t^{(i)}/(\sum_i^N{w_t^{(i)}})$.

4. 重采样：
从离散分布 $\widehat{p}(\boldsymbol{x}_{0:t}) = \sum_{i=1}^{N}{\widetilde{w}_{t}^{(i)}\delta(\boldsymbol{x}_{0:t}-\widehat{\boldsymbol{x}}_{0:t}^{(i)})}$ 中采样$N$个新轨迹，每个新轨迹权重为$(1/N)$，得到$\{\widetilde{\boldsymbol{x}}_{0:t}^{(i)}, \overline{w}_{t}^{(i)}=(1/N)|i=1,2,3...N\}$
5. MCMC move step : 
 - $\text{for }i=0,1,2....,N$
 - - 采样 $\boldsymbol{x}_{t}^{*}\sim q(\widetilde{\boldsymbol{x}}_{t}^{(i)}, \boldsymbol{x}_{t})$
 - - 采样 $\mu \sim \mathcal{U}_{[0,1]}$
 - - 如果  $\mu \le min \left\{1, \frac{\alpha(\widetilde{\boldsymbol{x}}_{t}^{(i)}, \boldsymbol{x}_{t}^{*})}{\alpha(\boldsymbol{x}_{t}^{*}, \widetilde{\boldsymbol{x}}_{t}^{(i)})}\right\}$，即$$\mu \le min \left\{1, \frac{[p(\boldsymbol{x}_{t}^{*}|\widetilde{\boldsymbol{x}}_{t-1}^{(i)})p(\boldsymbol{y}_{t}|\boldsymbol{x}_{t}^{*})]q(\boldsymbol{x}_{t}^{*}, \widetilde{\boldsymbol{x}}_{t}^{(i)})}{[p(\widetilde{\boldsymbol{x}}_{t}^{(i)}|\widetilde{\boldsymbol{x}}_{t-1}^{(i)})p(\boldsymbol{y}_{t}|\widetilde{\boldsymbol{x}}_{t}^{(i)})]q(\widetilde{\boldsymbol{x}}_{t}^{(i)}, \boldsymbol{x}_{t}^{*})}\right\}$$则接受转移，设置 $\boldsymbol{x}_{0:t}^{(i)}=[\widetilde{\boldsymbol{x}}_{0:t-1}^{(i)}, \boldsymbol{x}_{t}^{*}]$；
 - - 否则，拒绝转移，设置 $\boldsymbol{x}_{0:t}^{(i)}=\widetilde{\boldsymbol{x}}_{0:t}^{(i)}$；
 - $\text{end loop}$;
6. 输出结果，跳回2进入下一时刻；

为了提高转移率，我们应让$\frac{[p(\boldsymbol{x}_{t}^{*}|\widetilde{\boldsymbol{x}}_{t-1}^{(i)})p(\boldsymbol{y}_{t}|\boldsymbol{x}_{t}^{*})]q(\boldsymbol{x}_{t}^{*}, \widetilde{\boldsymbol{x}}_{t}^{(i)})}{[p(\widetilde{\boldsymbol{x}}_{t}^{(i)}|\widetilde{\boldsymbol{x}}_{t-1}^{(i)})p(\boldsymbol{y}_{t}|\widetilde{\boldsymbol{x}}_{t}^{(i)})]q(\widetilde{\boldsymbol{x}}_{t}^{(i)}, \boldsymbol{x}_{t}^{*})}$ 尽可能接近 $1$，因此最优的 kernel 是：
$$q(\widetilde{\boldsymbol{x}}_{t}^{(i)}, \boldsymbol{x}_{t}^{*}) \propto [p(\boldsymbol{x}_{t}^{*}|\widetilde{\boldsymbol{x}}_{t-1}^{(i)})p(\boldsymbol{y}_{t}|\boldsymbol{x}_{t}^{*})]$$
这样的 kernel 能保证转移率是$1$。但是这样的 kernel 一般也不容易采样：实际运用时必须保证所选的 kernel 是容易采样的。

如果状态转移分布 $p(\boldsymbol{x}_{t}|\boldsymbol{x}_{t-1}^{(i)})$ 容易采样，可以定义 $q(\widetilde{\boldsymbol{x}}_{t}^{(i)}, \boldsymbol{x}_{t}^{*}) \propto p(\boldsymbol{x}_{t}^{*}|\widetilde{\boldsymbol{x}}_{t-1}^{(i)})$，这样第5步的MCMC move可简化为：
 - $\text{for }i=0,1,2....,N$
 - - 采样 $\boldsymbol{x}_{t}^{*}\sim p(\boldsymbol{x}_{t}|\widetilde{\boldsymbol{x}}_{t-1}^{(i)})$
 - - 采样 $\mu \sim \mathcal{U}_{[0,1]}$
 - - 如果 $\mu \le min \left\{1, \frac{p(\boldsymbol{y}_{t}|\boldsymbol{x}_{t}^{*})}{p(\boldsymbol{y}_{t}|\widetilde{\boldsymbol{x}}_{t}^{(i)})}\right\}$ 则接受转移，设置 $\boldsymbol{x}_{0:t}^{(i)}=[\widetilde{\boldsymbol{x}}_{0:t-1}^{(i)}, \boldsymbol{x}_{t}^{*}]$；
 - - 否则，拒绝转移，设置 $\boldsymbol{x}_{0:t}^{(i)}=\widetilde{\boldsymbol{x}}_{0:t}^{(i)}$；
 - $\text{end loop}$;


> 从预备知识2中可以知道，利用 kernel $q(\widetilde{\boldsymbol{x}}_{0:t}, \boldsymbol{x}_{0:t})$和接受率函数$\alpha (\widetilde{\boldsymbol{x}}_{0:t}, \boldsymbol{x}_{0:t})$，可以构造一个能直接与目标分布$p(\boldsymbol{x}_{0:t}|\boldsymbol{y}_{1:t})$满足细致平稳条件的 kernel $q'(\widetilde{\boldsymbol{x}}_{0:t}, \boldsymbol{x}_{0:t})$，即：
$$ p(\widetilde{\boldsymbol{x}}_{0:t}|\boldsymbol{y}_{1:t}) q'(\widetilde{\boldsymbol{x}}_{0:t}, \boldsymbol{x}_{0:t}) =  p(\boldsymbol{x}_{0:t}|\boldsymbol{y}_{1:t}) q'(\boldsymbol{x}_{0:t}, \widetilde{\boldsymbol{x}}_{0:t})$$
而 MCMC move 其实等价于在重采样得到等权重样本集$\{\widetilde{\boldsymbol{x}}_{0:t}^{(i)}|i=1:N\}$后，从每个$q'(\widetilde{\boldsymbol{x}}_{0:t}^{(i)}, \boldsymbol{x}_{0:t})$中采样一个轨迹${\boldsymbol{x}_{0:t}^{(i)}}$，来替代对应的$\widetilde{\boldsymbol{x}}_{0:t}^{(i)}$。
而前面也提到 正则化(regularized)粒子滤波的操作，也等价于从每个$K^{(i)}(\boldsymbol{x}_{0:t}-\widetilde{\boldsymbol{x}}_{0:t}^{(i)})$中采样一个新轨迹${\boldsymbol{x}_{0:t}^{(i)}}$，来替代对应的$\widetilde{\boldsymbol{x}}_{0:t}^{(i)}$。
所以从这个角度看， MCMC move 可以看做 “正则化(regularized)粒子滤波” 的一个特例。相比于正则化方法，MCMC move 的优点是：它的 kernel 不像正则化滤波里选得那么盲目，它至少理论上保证了不改变轨迹的现有分布。

## 设计更好的 proposal 分布

### EKF 产生 proposal 分布

在重要性采样阶段，先为每个粒子运行一次 EKF，由此得到该粒子的 proposal 分布。
这样的 proposal 分布考虑了最新时刻的观测值，得到的分布更加接近真实分布；
proposal 分布与实际的状态分布越接近，得到的粒子权重就越均衡，能提升粒子滤波器的效果。
由于选择了比较好的proposal 分布，样本退化、贫化现象会减弱，一般不再需要 MCMC 步骤(该步骤是 optional 的)。

算法流程如下图：
![](https://github.com/NewThinker-Jeffrey/Figures/raw/main/figures/26773c9da1003c67658c92b6df8c45f1.png)

上图中步骤 2(C) 的 MCMC step 的具体操作如下： 
![](https://github.com/NewThinker-Jeffrey/Figures/raw/main/figures/142129f0873074dd59bafdb0eba65796.png)
 


### UPF (无迹粒子滤波)

- UPF 算法为每一个粒子维护一个 UKF，由 UKF 给出 proposal 分布。UKF能给出比EKF更好的 proposal 分布。
- $k$时刻的重要性采样阶段，每个粒子 $\boldsymbol{x}_k^{(i)}$，都是从一个以$(\overline{\boldsymbol{x}}_{k}^{(i)},\boldsymbol{P}_{k}^{(i)})$为均值和协方差矩阵的高斯分布(proposal)$\mathcal{N}(\overline{\boldsymbol{x}}_{k}^{(i)},\boldsymbol{P}_{k}^{(i)})$中采样得来，然后再进行跟通用粒子滤波中一样的重采样等步骤；
- UPF算法实现中，除了保存所有粒子$\boldsymbol{x}_k^{(i)}$本身，还要保存它们对应的$(\overline{\boldsymbol{x}}_{k}^{(i)},\boldsymbol{P}_{k}^{(i)})$。在重采样等步骤中，某个粒子 $\boldsymbol{x}_k^{(i)}$被丢弃后，与之对应的$(\overline{\boldsymbol{x}}_{k}^{(i)},\boldsymbol{P}_{k}^{(i)})$也会被丢弃；反之，某个粒子 $\boldsymbol{x}_k^{(i)}$被复制后，与之对应的$(\overline{\boldsymbol{x}}_{k}^{(i)},\boldsymbol{P}_{k}^{(i)})$也会被复制；MCMC move 过程中，某个粒子被移动，其所对应的$(\overline{\boldsymbol{x}}_{k}^{(i)},\boldsymbol{P}_{k}^{(i)})$保持不变。

UPF算法具体流程如下

 
![](https://github.com/NewThinker-Jeffrey/Figures/raw/main/figures/266b3838baeaa2e50f750d6a638a685f.png)
 
![](https://github.com/NewThinker-Jeffrey/Figures/raw/main/figures/4d460ee5d3d3f96b47ed7e799652fdbb.png)

![](https://github.com/NewThinker-Jeffrey/Figures/raw/main/figures/3ab13d5ce2ce4ad880bb595972b83fa0.png)



